{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Jan 2025\n",
    "\n",
    "The purpose of this notebook is to begin making improvements on my General Conference Breakdown program. \n",
    "\n",
    "Things I need to fix include the following: \n",
    "\n",
    "Functionality issues:\n",
    "* the calculator is printing out days after the readthrough is supposed to be finished. Currently, on these days, it prints out the start point as the paragraph after the final paragraph of the talk, and the end point as the final paragraph of the talk. \n",
    "* when exporting to a csv, special characters (like ones with accent marks) seem to be saving in something akin to unicode.\n",
    "* consider also saving the total number of paragraphs in the final breakdown, and maybe use short role instead of role.\n",
    "* make sure code can handle handle different and incorrect inputs (such as different date formats or just putting the wrong thing in as input)\n",
    "* descriptions of photographs are being counted as paragraphs, throwing off the count.\n",
    "* some talks ended up having the wrong number of counted paragraphs - this could be related to the photograph descriptions, or to something else in the code. \n",
    "\n",
    "Efficiency issues:\n",
    "* adjust function to save conference talks as their own information and draw information about them from it's memory, not export then re-import them. \n",
    "* adjust function to only drive to the web one time, rather than driving to the web to get information about the conference as a whole, then to navigate to it a second time to get information about each of the talks (so include the work done in the `get_talks` functions in the initial driver navigation)\n",
    "* remove unnecessary debugging print lines, implement more informative and useful ones until they are no longer needed. \n",
    "\n",
    "Later features:\n",
    "* enable the function to create a breakdown regardless of any information being missing, like start or end date, number of readthroughs, etc. \n",
    "* enable the function to be able to account for \"break days\"\n",
    "\n",
    "As I work through different issues, I will use the ~~strikethrough~~ markdown to indicate that an issue in the list above has been resolved. I will also include documentation in the markdowns below explaining how I approached fixing the issues. \n",
    "\n",
    "\n",
    "Before starting with anything else, though, I needed to first import the necessary packages and then divide the calculator function into separate parts or stages. This will help me handle things at different steps of the process without having to go through the whole breakdown process every time, and enable me to identify easily when and where my code is getting choked up. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import glob\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import re\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Jan 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, I tested the old calculator to ensure it was working properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breakdown_gc():\n",
    "    \"\"\"\n",
    "    This function takes all of the webscraping, cleaning, and manipulating I have done in other notebooks, and combines the entire process into one huge function that asks for significantly more user input. \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    ##### Setup #####\n",
    "    \n",
    "\n",
    "\n",
    "    # import necessary packages\n",
    "    import pandas as pd\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import os\n",
    "    import time\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.chrome.service import Service\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.chrome.options import Options\n",
    "    import glob\n",
    "    from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    from webdriver_manager.chrome import ChromeDriverManager\n",
    "    import re\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    # set working directory for accessing and saving files\n",
    "    os.chdir('d:\\\\Faith and Religion Stuff\\\\Come, Follow Me\\\\come-follow-me-breakdown-builder')\n",
    "\n",
    "    # ask for user input for link\n",
    "    conf_link = input('Please paste the link to the landing page of the conference you would like to breakdown.')\n",
    "\n",
    "    # ask for user input for year and month of conference\n",
    "    month = input('Please enter whether the conference was held in April or October: ').lower().replace('il','',1).replace('ober','',1)\n",
    "    year = input('Please enter the year of the conference: ').strip().replace('20','',1)\n",
    "    month_year = month + year\n",
    "\n",
    "    # ask for user input for the start date and end dates\n",
    "    ini_start = str(input(\"What day would you like to start reading?\"))\n",
    "    ini_end = str(input(\"What day would you like to stop reading?\"))\n",
    "\n",
    "    # Convert user input into datetime objects\n",
    "    ini_start_date = pd.to_datetime(ini_start,format='%m/%d/%Y')\n",
    "    ini_end_date = pd.to_datetime(ini_end,format='%m/%d/%Y')\n",
    "    \n",
    "    # Get the total number of days for the breakdown plan\n",
    "    ini_total_days = ini_end_date - (ini_start_date - timedelta(days=1))\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##### Getting information such as author, title, and description of each link on the conference landing page. #####\n",
    "\n",
    "\n",
    "\n",
    "    # get response\n",
    "    response = requests.get(conf_link)\n",
    "\n",
    "    # Define the path to the chromedriver executable\n",
    "    chrome_driver_dir = r'D:\\\\Faith and Religion Stuff\\\\Come, Follow Me\\\\chromedriver-win64'\n",
    "    chrome_driver_path = os.path.join(chrome_driver_dir, 'chromedriver.exe')\n",
    "\n",
    "    # Set up the headless browser options\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "\n",
    "    # Set up the Chrome service\n",
    "    service = Service(chrome_driver_path)    \n",
    "        \n",
    "    # Initialize the Chrome WebDriver\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    # Establish a try loop that tries to navigate to the provided link and find and store bits of info that we need \n",
    "    try:\n",
    "        # Navigate to the page with your elements - in this case the April 2024 General Conference\n",
    "        driver.get(conf_link)\n",
    "\n",
    "        # Find all elements with the specified class name\n",
    "        # Gotta use dots, not spaces, here because CSS considers each of those spaces to be defining a dif class object\n",
    "        elements = driver.find_elements(By.CSS_SELECTOR, 'a.sc-omeqik-0.ewktus.list-tile.listTile-WHLxI')  \n",
    "\n",
    "        # Initialize a list to store authors, titles, descriptions, and links\n",
    "        primary_meta_list = []\n",
    "        title_list = []\n",
    "        description_list = []\n",
    "        href_list = []\n",
    "\n",
    "        # Iterate over each element\n",
    "        # This for loop will, for all the videos/links to talks on the 2024 General Conference page, run through each of the following operations before moving onto the next\n",
    "        for element in elements:\n",
    "            # Try to get the author\n",
    "            try:\n",
    "                # Finds and stores the primary meta element (which is the author of the talk or report)\n",
    "                primary_meta_element = element.find_element(By.CSS_SELECTOR,'p.primaryMeta')\n",
    "                # Saves the stored author information as text\n",
    "                primary_meta = primary_meta_element.text\n",
    "            # If there is no author, save the author as None or Null\n",
    "            except:\n",
    "                primary_meta = None\n",
    "            # Adds the author (or the None) to the list of authors in the appropriate row\n",
    "            primary_meta_list.append(primary_meta)\n",
    "\n",
    "            # Try to get the title - every link/video should have a title\n",
    "            try:\n",
    "                # Finds and stores the title element (the title of the video, talk, or report)\n",
    "                title_element = element.find_element(By.CSS_SELECTOR,'p.title')\n",
    "                # Saves the stored title as text\n",
    "                title = title_element.text\n",
    "            # If there is no title, save the title as None - THIS SHOULD NEVER BE THE CASE\n",
    "            except:\n",
    "                title = None\n",
    "            # add the title (or the None) to the list of titles in the appropriate row\n",
    "            title_list.append(title)\n",
    "\n",
    "            # Try to get the description - the summary blurb about the video, talk, or report\n",
    "            try:\n",
    "                # Finds and stores the description element (the title of the video, talk, or report)\n",
    "                description_element = element.find_element(By.CSS_SELECTOR,'p.description')\n",
    "                # Saves the stored description as text\n",
    "                description = description_element.text\n",
    "            # If there is no description, save it as None - THIS SHOULD NEVER BE THE CASE\n",
    "            except:\n",
    "                description = None\n",
    "            # add the title (or the None) to the list of descriptions in the appropriate row\n",
    "            description_list.append(description)\n",
    "\n",
    "            # Finds and stores the link (or href) to the video, talk, or report\n",
    "            # This is ultimately going to be the information we use later to get the lengths (in paragraphs) of the talks and the lengths (in lines) of each of those paragraphs\n",
    "            href = element.get_attribute('href')\n",
    "            # Adds the stored href to the list of hrefs in the appropriate row\n",
    "            href_list.append(href)\n",
    "\n",
    "        # Creates a dataframe to store all the found and stored lists together\n",
    "        ini_conf_df = pd.DataFrame({\n",
    "            'Author': primary_meta_list,\n",
    "            'Title': title_list,\n",
    "            'Description': description_list,\n",
    "            'Link': href_list\n",
    "        })\n",
    "\n",
    "    # If anything doesn't work for some reason, tell why\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    # After running everything, close the driver we opened to collect the data\n",
    "    finally:\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "\n",
    "\n",
    "\n",
    "    ##### Removing things we don't need. #####\n",
    "    \n",
    "\n",
    "\n",
    "    # initialize empty list of rows that need to be dropped\n",
    "    rows_to_drop = []\n",
    "\n",
    "    # Adds the indexes (or row numbers) of rows to the list of rows to be dropped if there is either no Author or Description\n",
    "        ## This exclusionary list is easy to edit\n",
    "    for index,row in ini_conf_df.iterrows():\n",
    "        if row['Author'] == None:\n",
    "            rows_to_drop.append(index)\n",
    "        elif row['Description'] == None:\n",
    "            rows_to_drop.append(index)\n",
    "        elif 'Sustaining' in row['Title']:\n",
    "            rows_to_drop.append(index)\n",
    "        elif 'Audit' in row['Title']:\n",
    "            rows_to_drop.append(index)\n",
    "    \n",
    "    # Drops the rows in the list of rows to drop from the dataframe and resets the index\n",
    "        ## This eliminates from the dataframe the session videos and the sustaining of the officers of the Church\n",
    "    conf_df_1 = ini_conf_df.drop(rows_to_drop).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ##### Getting additional information about each talk. ##### \n",
    "\n",
    "\n",
    "\n",
    "    # Define function for getting the total number of lines all talks \n",
    "        ## This function uses the urls stored in the dataframe\n",
    "    def get_total_lines(url):\n",
    "        \"\"\"\n",
    "        This function was designed specifically to run using an already active webdriver to gather paragraph and line length information about a general conference talk.\n",
    "        First, it uses a webdriver to navigate to a url and then finds the paragraphs within a body block, and gets the size of the rectangles within which each of those paragraphs are assigned to appear. \n",
    "        Then, calculates the height of each line, saves that number as an integer, and calculates how many of those lines would fit into the assigned rectangle. \n",
    "        Then, it adds the paragraph number and the number of lines in that paragraph to the previously created dataframe.\n",
    "        Finally, it calculates and returns the total number of lines in the talk by getting the sum of all paragraph lengths in lines. \n",
    "        \"\"\"\n",
    "        # initialize empty dataframe \"data_list\", with columns \"paragraph\" and \"lines\" being initially populated with NA values\n",
    "        data_list = pd.DataFrame()\n",
    "        data_list['paragraph'] = pd.NA\n",
    "        data_list['lines'] = pd.NA\n",
    "\n",
    "        # Find all elements containing the text\n",
    "        paragraphs = driver.find_elements(By.CSS_SELECTOR, '.body-block p')\n",
    "\n",
    "        # Iterate over each paragraph element\n",
    "        for index, paragraph in enumerate(paragraphs, start=1):\n",
    "            # Log paragraph number, since the paragraphs are not numbered. \n",
    "            paragraph_number = index\n",
    "\n",
    "            # Get the bounding rectangle of the element\n",
    "            rect = paragraph.rect\n",
    "\n",
    "            # Calculate line height\n",
    "            line_height_str = driver.execute_script(\"return window.getComputedStyle(arguments[0]).getPropertyValue('line-height');\", paragraph)\n",
    "            line_height_numeric = int(re.search(r'\\d+', line_height_str).group())  # Extract numeric value from string\n",
    "\n",
    "            # Calculate number of lines\n",
    "            num_lines = rect['height'] // line_height_numeric\n",
    "\n",
    "            # Append data dictionary to list\n",
    "            data_list.at[index,'paragraph'] = paragraph_number\n",
    "            data_list.at[index, 'lines'] = num_lines\n",
    "\n",
    "            total_lines = sum(data_list['lines'])\n",
    "        \n",
    "        return total_lines\n",
    "    \n",
    "    # Initialize the Chrome WebDriver\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "    # Copy conf_df_1 to create a reversion point if necessary (it won't be)\n",
    "    conf_df_2 = conf_df_1.copy()\n",
    "    \n",
    "    # Initialize columns in the dataframe with NA values to later be filled\n",
    "    conf_df_2['time'] = pd.NA\n",
    "    conf_df_2['paragraphs'] = pd.NA\n",
    "    conf_df_2['lines'] = pd.NA\n",
    "    conf_df_2['role'] = pd.NA\n",
    "\n",
    "    # iterate the following over each row in the apr_2024_df dataframe\n",
    "    for index, row in conf_df_2.iterrows():\n",
    "        # for each row, when the function calls for title, url, and author it is looking for the Title, Link, and Author columns in that row, respectively\n",
    "        title = row['Title']\n",
    "        url = row['Link']\n",
    "        author = row['Author']\n",
    "\n",
    "        # run the driver, navigating to the linked page in the row currently being worked on\n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait for the page to load completely\n",
    "        driver.implicitly_wait(10)\n",
    "\n",
    "        # Simulate clicking the play button using the class attribute\n",
    "        try:\n",
    "            play_button = driver.find_element(By.CSS_SELECTOR, \"button.sc-1g7hsbc-0.bCKkuP.sc-bvqtyr-3.eKGiZd\")\n",
    "            play_button.click()\n",
    "            print(f\"Clicked the play button for {title} to start the media.\")\n",
    "        except:\n",
    "            # ### Added - attempt to find alternately labeled play button\n",
    "            print(\"Trying alternative play button selector.\")\n",
    "            try:\n",
    "                play_button = driver.find_element(By.CSS_SELECTOR, \"button.sc-1g7hsbc-0.lcWZjw.sc-bvqtyr-4.eYHLNi\")\n",
    "                play_button.click()\n",
    "                print(f\"Clicked the play button for {title} to start the media.\")\n",
    "            except:\n",
    "                print(f\"Play button for {title} not found.\")\n",
    "\n",
    "        # Wait for the video element to be present in the DOM\n",
    "        try:\n",
    "            video_element = WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_element_located((By.TAG_NAME, 'video'))\n",
    "            )\n",
    "            print(\"Video element found in the DOM.\")\n",
    "        except:\n",
    "            print(\"No video element found.\")\n",
    "\n",
    "        # Wait for a short period to allow the video to start loading\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Attempt to retrieve the video duration using JavaScript\n",
    "        try:\n",
    "            video_duration = driver.execute_script(\"\"\"\n",
    "                let video = document.querySelector('video');\n",
    "                if (video) {\n",
    "                    console.log('Video element is present, checking duration...');\n",
    "                    return video.duration;\n",
    "                } else {\n",
    "                    let audio = document.querySelector('audio');\n",
    "                    if (audio) {\n",
    "                        console.log('Audio element is present, checking duration...');\n",
    "                        return audio.duration;\n",
    "                    }\n",
    "                }\n",
    "                return null;  // No media element found\n",
    "            \"\"\")\n",
    "            \n",
    "            # if video_duration exists\n",
    "            if video_duration:\n",
    "                # print a message saying how long the talk is in seconds\n",
    "                print(f\"{title} duration: {video_duration:.2f} seconds\")\n",
    "                # save the duration into the dataframe in the same row\n",
    "                conf_df_2.at[index, 'time'] = video_duration\n",
    "            # otherwise, print a message saying no video or audio element was found for the talk\n",
    "            else:\n",
    "                print(f\"No video or audio element found for {title}.\")\n",
    "        \n",
    "        # If there is an error, say there was an error and what it was, and try to get the next piece of information       \n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving video duration for {title}: {e}\")\n",
    "\n",
    "        # attempt to find the body block\n",
    "        try:\n",
    "            paragraphs = driver.find_elements(By.CSS_SELECTOR, '.body-block p')\n",
    "            # if body block is found, find the number of paragraphs, and save that number to the dataframe in the same row\n",
    "            conf_df_2.at[index, 'paragraphs'] = len(paragraphs)\n",
    "            # print a message giving the length of the talk in paragraphs\n",
    "            print(f\"Paragraph length of {title}: {len(paragraphs)} paragraphs.\")\n",
    "\n",
    "            # Use the get_total_lines function to get the total number of lines in the talk\n",
    "            num_lines = get_total_lines(url)\n",
    "            \n",
    "            # save the number of lines to the dataframe in the same row\n",
    "            conf_df_2.at[index, 'lines'] = num_lines\n",
    "            \n",
    "            # print a message telling the number of lines in the talk\n",
    "            print(f\"Line length of {title}: {num_lines} lines.\")\n",
    "\n",
    "        # if there is an error or a problem, print a message saying what the problem was, and try to get the next piece of information \n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating lines and paragraphs for {title}: {e}\")\n",
    "        \n",
    "        # try to find the author role\n",
    "        try:\n",
    "            role = driver.find_element(By.CLASS_NAME, 'author-role')\n",
    "            # if there is one, save it to the dataframe in the same row\n",
    "            conf_df_2.at[index, 'role'] = role.text\n",
    "            # print a message displaying the role of the author\n",
    "            print(f\"Role of {author}: {role.text}\")\n",
    "        # if there is an error or a problem, print a message saying what the problem was and then move onto the next row\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving role for {author}: {e}\")\n",
    "\n",
    "    # Close the browser after all rows have been iterated through\n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "    # converts all numeric columns to integers for easier use later\n",
    "    conf_df_2['time'] = conf_df_2['time'].astype(int).round(0)\n",
    "    conf_df_2['paragraphs'] = conf_df_2['paragraphs'].astype(int)\n",
    "    conf_df_2['lines'] = conf_df_2['lines'].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "    ##### Establishing a primary key column and getting read and day weights\n",
    "    \n",
    "\n",
    "\n",
    "    # copy conf_df_2 to establish a reversion point\n",
    "    conf_df_3 = conf_df_2.copy()\n",
    "\n",
    "    # copies the role column onto a newly created short_role column\n",
    "    conf_df_3['short_role'] = conf_df_3['role']\n",
    "\n",
    "    # initializes a replacement dictionary to shorten information in newly created 'short_role' column\n",
    "    rep_dict = {}\n",
    "\n",
    "    # Adds specific shortenings of each role to the replacement dictionary\n",
    "        ## this list is also easily editable if any other office becomes prominently represented in future conferences\n",
    "        ## this list also puts members of the Presidency of the Seventy and of any other member of any other Quorum of the Seventy on equal ground       \n",
    "    for index, row in conf_df_3.iterrows():\n",
    "        if 'President of The Church'in row['role']:\n",
    "            rep_dict[row['short_role']] = 'President of the Church'\n",
    "        elif 'First Presidency' in row['role']:\n",
    "            rep_dict[row['short_role']] = 'First Presidency'\n",
    "        elif 'Quorum of the Twelve' in row['role']:\n",
    "            rep_dict[row['short_role']] = 'Quorum of the Twelve'\n",
    "        elif 'the Seventy' in row['role']:\n",
    "            rep_dict[row['short_role']] = 'Seventy'\n",
    "        elif 'Relief Society' in row['role']:\n",
    "            rep_dict[row['short_role']] = 'Relief Society Presidency'\n",
    "        elif 'Presiding' in row['role']:\n",
    "            rep_dict[row['short_role']] = 'Presiding Bishopric'\n",
    "        elif 'Sunday School' in row['role']:\n",
    "            rep_dict[row['short_role']] = 'Sunday School Presidency'\n",
    "        elif 'Young Men' in row['role']:\n",
    "            rep_dict[row['short_role']] = 'Young Men Presidency'\n",
    "        elif 'Young Women' in row['role']:\n",
    "            rep_dict[row['short_role']] = 'Young Women Presidency'\n",
    "        elif 'Primary' in row['role']:\n",
    "            rep_dict[row['short_role']] = 'Primary Presidency'\n",
    "        else:\n",
    "            rep_dict[row['short_role']] = 'other speakers'\n",
    "    \n",
    "    # uses replacement dictionary to replace (shorten) all the entries in the short_role column\n",
    "    for words, replacement in rep_dict.items():\n",
    "        conf_df_3['short_role'] = conf_df_3['short_role'].replace(words, replacement).str.strip()\n",
    "    \n",
    "    # defines function to get the initials of the speaker for use in creation of primary key column\n",
    "    def get_initials(full_name):\n",
    "        parts = full_name.split()\n",
    "        initials = [part[0].lower() for part in parts]\n",
    "        return ''.join(initials)\n",
    "\n",
    "    # Create a new column with initials\n",
    "    conf_df_3['initials'] = conf_df_3['Author'].apply(get_initials)\n",
    "\n",
    "    # create a primary key column that combines the initials of the speaker and the month and year of the conference\n",
    "    conf_df_3['pk'] = (conf_df_3['initials'] + \"_\" + month_year)\n",
    "\n",
    "    # initialize an empty list of read weights\n",
    "    read_weights = []\n",
    "\n",
    "    # for every unique role code in the role_code column of the apr_2024_info dataframe...\n",
    "    for short_role in conf_df_3.short_role.unique():\n",
    "        # ... ask the user what the read weight should be and...\n",
    "        read_weight = int(input(f\"How many times would you like to read talks given by the {short_role}?\"))\n",
    "        # ... save both the role code and the read weight to the read_weights list\n",
    "        read_weights.append({'short_role':short_role, 'read_weight':read_weight})\n",
    "\n",
    "    # convert the read_weights list to a dataframe, save with the same name to replace the old item\n",
    "    read_weights = pd.DataFrame(read_weights)\n",
    "\n",
    "    # left-merge the read_weights dataframe to the apr_2024_info dataframe useing the role_code columns as a guide for merging\n",
    "    # left-merge keeps everything in the dataframe being merged to, and only merges data from the second dataframe that has a corresponding value in the original dataframe\n",
    "    conf_df_3 = conf_df_3.merge(read_weights, on='short_role',how='left')\n",
    "\n",
    "    # initialize an empty list of day weights\n",
    "    day_weights = []\n",
    "\n",
    "    # for every unique role code in the role_code column of the apr_2024_info dataframe...\n",
    "    for short_role in conf_df_3.short_role.unique():\n",
    "        # ... ask the user what the day weight should be and...\n",
    "        day_weight = int(input(f\"How many more or fewer days would you like to spend on talks given by the {short_role}?\\n\"\n",
    "                               f\"\\nIf you want to spend more days reading talks from the {short_role}, enter a number above 0.\\n\"\n",
    "                               f\"\\nOr if you want to spend fewer days reading talks from the {short_role}, enter a number below 0 by using a minus sign or dash.\\n\"\n",
    "                               f\"\\nIf you would rather spend a relatively the same amount of time on each talk from this organization as others, enter 0.\"))\n",
    "        # ... save both the role code and the day weight to the read_weights list\n",
    "        day_weights.append({'short_role':short_role, 'day_weight':day_weight})\n",
    "\n",
    "    # convert the read_weights list to a dataframe, save with the same name to replace the old item\n",
    "    day_weights = pd.DataFrame(day_weights)\n",
    "\n",
    "    # left-merge the read_weights dataframe to the apr_2024_info dataframe useing the role_code columns as a guide for merging\n",
    "    # left-merge keeps everything in the dataframe being merged to, and only merges data from the second dataframe that has a corresponding value in the original dataframe\n",
    "    conf_df_3 = conf_df_3.merge(day_weights, on='short_role',how='left')\n",
    "    \n",
    "\n",
    "\n",
    "    ##### Getting information about each talk\n",
    "\n",
    "\n",
    "\n",
    "    # save a copy of conf_df_3 as a reversion point\n",
    "    conf_df_4 = conf_df_3.copy()\n",
    "\n",
    "    # define a function that takes a link and gets the text and counts the lines of text of each talk given in the linked conference\n",
    "    def get_talks(talk_link):\n",
    "        \"\"\"\n",
    "        This function finds the description and text of a talk found at the talk link, numbers each paragraph of that talk and gets the text and length in lines of each paragraph. It returns as a dataframe all this information about each talk. \n",
    "        \"\"\"\n",
    "\n",
    "        # Define the path to the chromedriver executable\n",
    "        chrome_driver_dir = r'D:\\\\Faith and Religion Stuff\\\\Come, Follow Me\\\\chromedriver-win64'\n",
    "        chrome_driver_path = os.path.join(chrome_driver_dir, 'chromedriver.exe')\n",
    "\n",
    "        # Set up the headless browser options\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "\n",
    "        # Set up the Chrome service\n",
    "        service = Service(chrome_driver_path)    \n",
    "        \n",
    "        # Initialize the Chrome WebDriver\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "        # Run the driver\n",
    "        driver.get(talk_link)\n",
    "\n",
    "        # Initialize a list to store data dictionaries\n",
    "        data_list = []\n",
    "\n",
    "        # Try to get the description - the summary blurb about the video, talk, or report\n",
    "        try:\n",
    "            # Finds and stores the description (kicker) element (the title of the video, talk, or report)\n",
    "            description_element = driver.find_element(By.CSS_SELECTOR,'p.kicker')\n",
    "            # Saves the stored description as text\n",
    "            description = description_element.text\n",
    "\n",
    "            # set paragraph number for description as 0\n",
    "            paragraph_number = 0\n",
    "            \n",
    "            # Get the bounding rectangle of the element\n",
    "            rect = description_element.rect\n",
    "\n",
    "            # Calculate line height\n",
    "            line_height_str = driver.execute_script(\"return window.getComputedStyle(arguments[0]).getPropertyValue('line-height');\", description_element)\n",
    "            line_height_numeric = int(re.search(r'\\d+', line_height_str).group())  # Extract numeric value from string\n",
    "\n",
    "            # Calculate number of lines\n",
    "            num_lines = rect['height'] // line_height_numeric\n",
    "\n",
    "            # add text of and information about description to the data_list dictionary\n",
    "            data_list.append({\n",
    "                'paragraph_number': paragraph_number,\n",
    "                'num_lines': num_lines,\n",
    "                'text': description\n",
    "            })\n",
    "\n",
    "        # If there is no description, save it as None - THIS SHOULD NEVER BE THE CASE\n",
    "        except:\n",
    "            description = None\n",
    "\n",
    "        # Find all elements containing the text\n",
    "        paragraphs = driver.find_elements(By.CSS_SELECTOR, '.body-block p')\n",
    "\n",
    "        # Iterate over each paragraph element\n",
    "        for index, paragraph in enumerate(paragraphs, start=1):\n",
    "            # Get the text of the element\n",
    "            text = paragraph.text\n",
    "\n",
    "            # Log paragraph number, since the paragraphs are not numbered. \n",
    "            paragraph_number = index\n",
    "\n",
    "            # Get the bounding rectangle of the element\n",
    "            rect = paragraph.rect\n",
    "\n",
    "            # Calculate line height\n",
    "            line_height_str = driver.execute_script(\"return window.getComputedStyle(arguments[0]).getPropertyValue('line-height');\", paragraph)\n",
    "            line_height_numeric = int(re.search(r'\\d+', line_height_str).group())  # Extract numeric value from string\n",
    "\n",
    "            # Calculate number of lines\n",
    "            num_lines = rect['height'] // line_height_numeric\n",
    "\n",
    "            # Append data dictionary to list\n",
    "            data_list.append({\n",
    "                'paragraph_number': paragraph_number,\n",
    "                'num_lines': num_lines,\n",
    "                'text': text\n",
    "            })\n",
    "\n",
    "        # Convert list of dictionaries to DataFrame\n",
    "        df = pd.DataFrame(data_list)\n",
    "\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "        return df\n",
    "    \n",
    "    # Define directory path for saving CSV files\n",
    "    dir_path = input(f'Please paste here the location of the folder in which you would like to store information from this general conference.\\n'\n",
    "                     f'\\nExample:    D:\\\\Faith and Religion Stuff\\\\Come, Follow Me Breakdowns\\\\April 2024 GC Talks\\n'\n",
    "                     f'\\nThis will require you to have already created a folder in which you want the information for the talks to be saved.')\n",
    "\n",
    "    # establish a loop that iterates through every row of the conference dataframe\n",
    "    for index, row in conf_df_4.iterrows():\n",
    "        # save information from the 'Title' row as title\n",
    "        title = row['Title']\n",
    "        # save information from the 'Link' row as link\n",
    "        link = row['Link']\n",
    "        # save information from the 'pk' Primary Key row as foreign_key\n",
    "        foreign_key = row['pk']\n",
    "\n",
    "        # using the saved link, create a dataframe that contains the paragraph line counts information for the talk in the current row \n",
    "        talk_lines_df = get_talks(link)\n",
    "\n",
    "        # if the created dataframe is not populated with None data and is not empty:\n",
    "        if talk_lines_df is not None and not talk_lines_df.empty:\n",
    "            # creates a new column in the dataframe that uses the primary key of the talk as the foreign key\n",
    "            talk_lines_df['foreign_key'] = foreign_key\n",
    "            # Uses a lambda function to create a primary key for each paragraph consisting of the foreign key + the paragraph number\n",
    "            talk_lines_df['pk'] = talk_lines_df.apply(lambda x:f\"{foreign_key}_{x.get('paragraph_number')}\", axis=1)\n",
    "        \n",
    "            # very rudimentarily define which columns to keep, and add column names to that list in the desired order\n",
    "            columns_to_keep = ['foreign_key','pk']\n",
    "            columns_to_keep.append('paragraph_number')\n",
    "            columns_to_keep.append('text')\n",
    "            columns_to_keep.append('num_lines')\n",
    "\n",
    "            # save dataframe with columns in the order specified in the columns_to_keep list\n",
    "            talk_lines_df = talk_lines_df[columns_to_keep]\n",
    "            \n",
    "            # save file name\n",
    "            csv_filename = f'{foreign_key}_lines.csv'\n",
    "            # combine the file name and the user inputted folder location to create a complete save path\n",
    "            full_path = os.path.join(dir_path,csv_filename)\n",
    "\n",
    "            # Debugging line to state where files can be found\n",
    "            print(f'Saving to: {full_path}')\n",
    "\n",
    "            # export dataframe as a csv file to the location specified\n",
    "            talk_lines_df.to_csv(full_path, index = False)\n",
    "            # print message saying that csv file has been created\n",
    "            print(f'CSV file for \"{title}\" saved successfully as {csv_filename}.')\n",
    "        \n",
    "        # otherwise, if the dataframe is filled with None values or is empty\n",
    "        else:\n",
    "            # print a message saying no data was found for the talk\n",
    "            print(f'No data found for \"{title}\", skipping CSV creation.')\n",
    "    \n",
    "    ### stupidly import data I just exported because I don't have the bandwidth to come up with another solution and want to go to bed ###\n",
    "\n",
    "    # define the beginning of the file location\n",
    "        ## this is done by accessing the dir_path given by the user, and adding \\\\ to the end of it.\n",
    "    path_start = f'{dir_path}\\\\'\n",
    "\n",
    "    # initialize filenames list\n",
    "    csv_files = []\n",
    "\n",
    "    # get the names of all the csv files in the directory\n",
    "    for file in os.listdir(path_start):\n",
    "        if file.endswith(\".csv\"):\n",
    "            csv_files.append(file)\n",
    "\n",
    "    # initialize a dictionary to store the dataframes\n",
    "    all_talks_dict = {}\n",
    "\n",
    "    # import the csv files into pandas dataframes, store each dataframe in the dictionary\n",
    "    for file in csv_files:\n",
    "        talk = file[:-4]\n",
    "        all_talks_dict[talk] = pd.read_csv(os.path.join(path_start, file))\n",
    "        print(f'file string: {file}\\n'\n",
    "            f'talk string: {talk}')\n",
    "\n",
    "    # iterate over every dataframe stored in the all_talks_df dictionary\n",
    "    for talk, df in all_talks_dict.items():\n",
    "        # create a new column in each dataframe that is the cumulative sum of the number of lines\n",
    "        df['running_lines'] = df['num_lines'].cumsum()\n",
    "\n",
    "\n",
    "    \n",
    "    ##### Assigning a number of days for each readthrough of each talk #####\n",
    "\n",
    "\n",
    "    \n",
    "    # Since conf_df_4 was not altered in anyway during the previous major step, we don't need to save a copy\n",
    "\n",
    "    # Get some information about the conference as a whole\n",
    "    total_time = sum(conf_df_4['time'])\n",
    "    total_lines = sum(conf_df_4['lines'])\n",
    "    \n",
    "    # create a new conference consumption column that gives a proportional weight to each talk based on it's length and user input\n",
    "    conf_df_4['conf_cons'] = (\n",
    "        ((1/32) +                                                                  # Each talk is 1 of 32 given, this treats each equally\n",
    "        conf_df_4['time']/total_time +                                             # time weight - longer \"heavier\"\n",
    "        conf_df_4['lines']/total_lines +                                           # lines weight - longer \"heavier\"\n",
    "        ((conf_df_4['day_weight'] + 1)/(conf_df_4['day_weight'] + 1).sum()))       # preference weight - user input factors in here\n",
    "        / 4                                                                        # Adding each of those and then dividing by 4 gets the average\n",
    "    )\n",
    "    \n",
    "    # create a column with the total number of days to be spent on each talk\n",
    "        ## multiply the number of days specified in the plan by the conference consumption ratio\n",
    "    conf_df_4['tot_num_days'] = ini_total_days.days * conf_df_4['conf_cons']\n",
    "    conf_df_4['tot_num_days'] = conf_df_4['tot_num_days'].round()\n",
    "\n",
    "    # convert the newly created column into integers rather than floats\n",
    "    conf_df_4['tot_num_days'] = conf_df_4['tot_num_days'].astype(int)\n",
    "\n",
    "    # find and save the highest number in the read_weights column\n",
    "    max_reads = conf_df_4.read_weight.max()\n",
    "\n",
    "    # start a loop that, for every number between 1 and whatever the max_reads number is, inclusive...\n",
    "    for i in range(1,max_reads+1):\n",
    "        # create a new column of NA values titled \"Readthrough # _(whatever number the loop is on)_\"\n",
    "        conf_df_4[f\"Readthrough #{i}\"] = pd.NA\n",
    "        \n",
    "    # convert all NA values to \"0\"\n",
    "    conf_df_4.fillna(0, inplace=True)\n",
    "\n",
    "    def distribute_days(conf_df):\n",
    "        \"\"\"\n",
    "        This function takes a dataframe like the one I have crafted above and distributes the total number of days into the \"Readthrough #_\" columns.\n",
    "        \"\"\"\n",
    "        # establish that the function needs to repeat for every row of the dataframe\n",
    "        for index, row in conf_df.iterrows():\n",
    "            # get total number of days for that talk\n",
    "            total_days = row['tot_num_days']\n",
    "            # initialize number of distributed days as 0\n",
    "            dist_days = 0\n",
    "            # establish that the function needs to proceed with the following operation until dist_days and total_days are equal\n",
    "            while dist_days < total_days:\n",
    "                # for every whole number between 1 and whatever the read_weight (or number of readthroughs) is...\n",
    "                for i in range(1,row['read_weight']+1):\n",
    "                    # if dist_days is still less than total_days...\n",
    "                    if dist_days < total_days:\n",
    "                        # add 1 to whatever value is in the \"Readthrough #(number between 1 and number of readthroughs)\" column and...\n",
    "                        conf_df.at[index, f'Readthrough #{i}'] += 1\n",
    "                        # add 1 to dist_days\n",
    "                        dist_days += 1\n",
    "                        # go back to add 1 to the next column until dist_days is no longer less than total_days\n",
    "                    # if/when dist_days is equal to total_days\n",
    "                    else:\n",
    "                        # break the process of adding one to each column, and move on to the next row to start the process over\n",
    "                        break\n",
    "        # when everything is done, the output of this function is the same dataframe with all of the updated columns\n",
    "        return conf_df\n",
    "\n",
    "    # run the function on my dataframe\n",
    "    conf_df_5 = distribute_days(conf_df_4)\n",
    "\n",
    "\n",
    "\n",
    "    ##### Distributing lines from each talk across each day of each readthrough #####\n",
    "\n",
    "    # Use a series of loops to create a line start, number of lines, line end, paragraph start, and paragraph end column for every day of every readthrough of every talk\n",
    "    for i in range(1, conf_df_5['read_weight'].max()+1):\n",
    "        for x in range(1, conf_df_5[f'Readthrough #{i}'].max()+1):\n",
    "            for index, row in conf_df_5.iterrows():\n",
    "                if row[f'Readthrough #{i}'] != 0:\n",
    "                    conf_df_5.at[index, f'r{i}d{x}_l_start'] = int(0)\n",
    "                    conf_df_5.at[index, f'r{i}d{x}_lines'] = int(0)\n",
    "                    conf_df_5.at[index, f'r{i}d{x}_l_end'] = int(0)\n",
    "                    conf_df_5.at[index, f'r{i}d{x}_p_start'] = int(0)\n",
    "                    conf_df_5.at[index, f'r{i}d{x}_p_end'] = int(0)\n",
    "                else:\n",
    "                    conf_df_5.at[index, f'r{i}d{x}_l_start'] = pd.NA\n",
    "                    conf_df_5.at[index, f'r{i}d{x}_lines'] = pd.NA\n",
    "                    conf_df_5.at[index, f'r{i}d{x}_l_end'] = pd.NA\n",
    "                    conf_df_5.at[index, f'r{i}d{x}_p_start'] = pd.NA\n",
    "                    conf_df_5.at[index, f'r{i}d{x}_p_end'] = pd.NA\n",
    "    \n",
    "    # establishes a regular expression pattern\n",
    "    pattern = r'\\D\\d\\D\\d+'\n",
    "    # identifies columns that are floats and not integers\n",
    "    float_cols = conf_df_5.select_dtypes(include=['float'])\n",
    "    # targets specific float columns using regular expression pattern\n",
    "    change_cols = [col for col in float_cols if re.search(pattern, col)]\n",
    "    # converts targeted columns to integers\n",
    "    conf_df_5[change_cols] = conf_df_5[change_cols].astype(int)\n",
    "\n",
    "    # I struggled for about 5 hours because I forgot this step. Including it was as simple as a copy paste.\n",
    "    # This also came in answer to my prayer for help. I prayed for God to help me know where to look, and this was the next thing I looked at. \n",
    "    # God is good. \n",
    "    \n",
    "    def distribute_lines(conf_df):\n",
    "        \"\"\"\n",
    "        This function takes a dataframe like the one I have crafted above and distributes the total number of days into the \"Readthrough #_\" columns.\n",
    "        \"\"\"\n",
    "        # initialize readthrough count as zero\n",
    "        readthrough = 0\n",
    "        # establish maximum number of readthroughs so the loop I create below knows when to end or stop\n",
    "        max_readthroughs = conf_df['read_weight'].max()\n",
    "        # start a loop of action that will continue until readthroughs is bigger than max_readthroughs, at which point it will stop\n",
    "        while readthrough <= max_readthroughs:\n",
    "            # A - first action: add 1 to readthroughs, establishing which readthrough we are working with\n",
    "            readthrough += 1\n",
    "            # B - Check if the current readthrough exists in the DataFrame\n",
    "            if f'Readthrough #{readthrough}' not in conf_df.columns:\n",
    "                break  # If the column doesn't exist, exit the loop\n",
    "\n",
    "            # C - second action: for every row in the dataframe do the following:\n",
    "            for index, row in conf_df.iterrows():\n",
    "                # D - second action, cont'd: save the info in the row 'lines' as the total number of lines to be distributed\n",
    "                total_lines = row['lines']\n",
    "                # E - second action, cont'd: initialize count of distributed lines as zero\n",
    "                dist_lines = 0\n",
    "                # debugging print line - remove later\n",
    "                print(f\"Row {index} - Readthrough {readthrough} has {row[f'Readthrough #{readthrough}']} days.\")\n",
    "                # F - check whether the number of days assigned to a talk in a particular readthrough is 0\n",
    "                if row[f'Readthrough #{readthrough}'] == 0:\n",
    "                    # debugging print line - remove later\n",
    "                    print(f\"Skipping row {index} - Readthrough {readthrough} because it has 0 days.\")\n",
    "                    # if that talk has zero days alloted for that readthrough, skip to the next talk\n",
    "                    continue\n",
    "                \n",
    "                # G - second action, cont'd: open another while loop that will continue until the number of distributed lines is equal to the number of total lines\n",
    "                while dist_lines < total_lines:\n",
    "                    # H - first action of second loop: open another loop that operates i number of times, where i is the number of days in the readthrough\n",
    "                    for i in range(1, row[f'Readthrough #{readthrough}']+1):\n",
    "                        # debugging print line - remove later\n",
    "                        print(f\"Processing row {index}, readthrough {readthrough}, day {i}.\")\n",
    "                        # I - first action of second loop, cont'd: add 1 to the corresponding i day of the current readthrough\n",
    "                        conf_df.at[index, f'r{readthrough}d{i}_lines'] += 1\n",
    "                        # J - first action of second loop, cont'd: add 1 to the number of distributed lines\n",
    "                        dist_lines += 1\n",
    "                        # debugging print line - remove later\n",
    "                        print(f\"Distributed lines: {dist_lines}/{total_lines}\")\n",
    "                        # K - check if dist_lines is less than total_lines: \n",
    "                        if dist_lines >= total_lines:\n",
    "                            break\n",
    "                            # Unstated action: If it is less, return to point H and repeat this loop.\n",
    "                            # If not, end *this* loop and return to point D for the next row.\n",
    "                    \n",
    "            # L - check if readthroughs is less than or equal to max_readthroughs\n",
    "            if readthrough > max_readthroughs:\n",
    "                # If it is, repeat this loop, starting with point A\n",
    "                break\n",
    "                # Unstated action: If not, end this loop and go to point M.\n",
    "        \n",
    "        # M - return the newly modified dataframe\n",
    "        return conf_df\n",
    "    \n",
    "    conf_df_5 = distribute_lines(conf_df_5)\n",
    "    \n",
    "    ##### Assigning lines and paragraphs for each day of each readthrough. Final Major Step. #####\n",
    "\n",
    "\n",
    "    # save a copy of conf_df_5 as a reversion point\n",
    "    conf_df_6 = conf_df_5.copy()\n",
    "    \n",
    "\n",
    "    def get_paragraphs(conf_df,talks_dictionary):\n",
    "        \"\"\"\n",
    "        This function assigns starting and ending lines and paragraphs for each day of each readthrough of each talk contained in the conference dataframe.\n",
    "        \"\"\"    \n",
    "        # initialize readthrough count as 0\n",
    "        rt = 0\n",
    "        # establish maximum number of readthroughs so the loop I create below knows when to end or stop\n",
    "        max_rts = conf_df['read_weight'].max()\n",
    "        # create a list of the column names in the given dataframe\n",
    "        cols = list(conf_df.columns)\n",
    "        # start a loop of action that will continue until readthroughs is bigger than max_readthroughs, at which point it will stop\n",
    "        while rt <= max_rts:\n",
    "            # A - first action: add 1 to readthroughs, establishing which readthrough we are working with\n",
    "            rt += 1\n",
    "            # debugging line - remove later\n",
    "            print(f'Starting readthrough {rt}.')\n",
    "            # B - Check if the current readthrough exists in the DataFrame\n",
    "            if f'Readthrough #{rt}' not in conf_df.columns:\n",
    "                # debugging line - remove later\n",
    "                print(f'Readthrough {rt} not found. Function complete.')\n",
    "                # if a column for the current readthrough number doesn't exist, exit the loop\n",
    "                break\n",
    "\n",
    "            # C-1 - Second action: start another loop that does the follow for the highest number of days in whatever readthrough number the function is on\n",
    "            for day in range(1, conf_df[f'Readthrough #{rt}'].max()+1):\n",
    "                \n",
    "                # debugging line - remove later\n",
    "                print(f'Working through readthrough {rt} day {day}.')\n",
    "\n",
    "                # C-2 - set patterns for pulling out info for the start, lines, end, and start of next day\n",
    "                rt_start_l_pattern = fr'r{rt}d{day}_l_start'\n",
    "                rt_lines_pattern = fr'r{rt}d{day}_lines'\n",
    "                rt_end_l_pattern = fr'r{rt}d{day}_l_end'\n",
    "                rt_next_start_l_pattern = fr'r{rt}d{day+1}_l_start'\n",
    "                rt_start_p_pattern = fr'r{rt}d{day}_p_start'\n",
    "                rt_end_p_pattern = fr'r{rt}d{day}_p_end'\n",
    "                rt_next_start_p_pattern = fr'r{rt}d{day+1}_p_start'\n",
    "\n",
    "                # debugging line - remove later\n",
    "                print(f'Readthrough {rt} day {day} patterns saved.')\n",
    "\n",
    "                # C-3 - initialize variables as empty lists\n",
    "                start_l_col = []\n",
    "                lines_col = []\n",
    "                end_l_col = []\n",
    "                next_start_l_col = []\n",
    "                start_p_col = []\n",
    "                end_p_col = []\n",
    "                next_start_p_col = []\n",
    "\n",
    "                # debugging line - remove later\n",
    "                print(f'Variables initialized.')\n",
    "\n",
    "                # C-4 - search for and save columns defined in patterns\n",
    "                for col in cols:\n",
    "                    if re.search(rt_start_l_pattern, col):\n",
    "                        start_l_col.append(col)\n",
    "                    elif re.search(rt_lines_pattern, col):\n",
    "                        lines_col.append(col)\n",
    "                    elif re.search(rt_end_l_pattern, col):\n",
    "                        end_l_col.append(col)\n",
    "                    elif re.search(rt_next_start_l_pattern, col):\n",
    "                        next_start_l_col.append(col)\n",
    "                    elif re.search(rt_start_p_pattern, col):\n",
    "                        start_p_col.append(col)\n",
    "                    elif re.search(rt_end_p_pattern, col):\n",
    "                        end_p_col.append(col)\n",
    "                    elif re.search(rt_next_start_p_pattern, col):\n",
    "                        next_start_p_col.append(col)\n",
    "\n",
    "                # debugging line - remove later\n",
    "                print(f'Columns found and saved.'\n",
    "                    f'Starting column name: {start_l_col}'\n",
    "                    f'Number of lines column: {lines_col}'\n",
    "                    f'End column name: {end_l_col}'\n",
    "                    f'Next start column name: {next_start_l_col}'\n",
    "                    f'Starting column name: {start_p_col}'\n",
    "                    f'Number of lines column: {lines_col}'\n",
    "                    f'End column name: {end_p_col}'\n",
    "                    f'Next start column name: {next_start_p_col}')\n",
    "                \n",
    "                # C-5-a -Start another loop\n",
    "                for index, row in conf_df.iterrows():\n",
    "                    # C-5-b - check if the number of days assigned for the current readthrough of the current talk is 0\n",
    "                    if row[f'Readthrough #{rt}'] == 0:\n",
    "                        # debugging print line - remove later\n",
    "                        print(f\"Skipping row {index} - Readthrough {rt} because it has 0 days.\")\n",
    "                        # if that talk has zero days alloted for that readthrough, skip to the next talk\n",
    "                        continue\n",
    "                    \n",
    "                    # unstated action - if the number of days assigned for the current readthrough is greater than zero, proceed to C-5-c\n",
    "\n",
    "                    # C-5-c - establish the connection between conf_df and talks_dict using the primary key column of the conf_df\n",
    "                    talk = talks_dictionary[f\"{conf_df.loc[index,'pk']}_lines\"]\n",
    "\n",
    "                    # debugging line - remove later\n",
    "                    print(f'Connecting conf_df to talks_dict using primary key {conf_df.loc[index,\"pk\"]}.')\n",
    "\n",
    "                    # C-5-d - check if the day number is 1\n",
    "                    if day == 1:\n",
    "                        # C-5-d-1 - if so, initialize the start column as 1 for every row\n",
    "                        conf_df[start_l_col] = 1\n",
    "                        conf_df[start_p_col] = 1\n",
    "                        # debugging line - remove later\n",
    "                        print(f'Readthrough {rt} day {day} set at 1.')\n",
    "                        # C-5-d-1 - then save the end point as the start point (1) plus the number of lines to be read \n",
    "                        # the minus 1 at the end ensures that we end at the assigned reading line, not the line after\n",
    "                        for start, read, end in zip(start_l_col, lines_col, end_l_col):\n",
    "                            conf_df.loc[index, end] = conf_df.loc[index, start] + conf_df.loc[index, read] - 1\n",
    "                        # C-5-d-2 - then save today's ending point as the starting point for the next day, to be accessed later\n",
    "                        for end, next_start in zip(end_l_col, next_start_l_col):\n",
    "                            conf_df.loc[index, next_start] = conf_df.loc[index, end]\n",
    "                        # C-5-d-3 - save the end line just calculated as object 'end_line'\n",
    "                        end_line = conf_df.loc[index, f'r{rt}d{day}_l_end']\n",
    "\n",
    "                        # debugging line - remove later\n",
    "                        print(f'Readthrough {rt} day {day} end line set. End line: {end_line}')\n",
    "\n",
    "                        # C-5-d-4 - find in the talk the paragraph with a running total that is greater than or equal to the end line \n",
    "                        end_paragraph_1 = talk.loc[talk['running_lines'] >= end_line].index[0]\n",
    "                        # C-5-d-5 - find in the talk the paragraph before the one above\n",
    "                        end_paragraph_2 = talk.loc[talk['running_lines'] >= end_line].index[-1]\n",
    "                        # C-5-d-6 - determine which paragraph would yield a number of lines being read closer to the target end line and save as end_paragraph\n",
    "                        if abs(talk.loc[end_paragraph_1,'running_lines'] - end_line) < abs(talk.loc[end_paragraph_2,'running_lines']- end_line):\n",
    "                            end_paragraph = end_paragraph_1\n",
    "                        else:\n",
    "                            end_paragraph = end_paragraph_2\n",
    "                        # C-5-d-7 - save the selected end_paragraph as the paragraph ending point of the current day of the current readthrough\n",
    "                        for end_p in end_p_col:\n",
    "                            conf_df.loc[index, end_p] = end_paragraph\n",
    "                        \n",
    "                        for end_p, next_start_p in zip(end_p_col, next_start_p_col):\n",
    "                            conf_df.loc[index, next_start_p] = conf_df.loc[index, end_p] + 1\n",
    "\n",
    "                        # debugging line - remove later\n",
    "                        print(f'Readthrough {rt} day {day} end paragraph set: End paragraph: {end_paragraph}')\n",
    "                        \n",
    "\n",
    "                        \n",
    "                    \n",
    "                    # C-5-e - if the day number IS NOT 1...\n",
    "                    else:\n",
    "                        # C-5-e-1 - access whatever the start column has already been saved as, add the number of lines, and save that as the end point\n",
    "                        for start, read, end in zip(start_l_col, lines_col, end_l_col):\n",
    "                            conf_df.loc[index, end] = conf_df.loc[index, start] + conf_df.loc[index, read]\n",
    "                        # C-5-e-2 - then save today's ending point as the starting point for the next day, to be accessed later\n",
    "                        for end, next_start in zip(end_l_col, next_start_l_col):\n",
    "                            conf_df.loc[index, next_start] = conf_df.loc[index, end]\n",
    "                        # C-5-e-3 - save the end line just calculated as object 'end_line'\n",
    "                        end_line = conf_df.loc[index, f'r{rt}d{day}_l_end']\n",
    "\n",
    "                        # debugging line - remove later\n",
    "                        print(f'Readthrough {rt} day {day} end line set. End line: {end_line}')\n",
    "\n",
    "                        # C-5-e-4 - find in the talk the paragraph with a running total that is greater than or equal to the end line \n",
    "                        end_paragraph_1 = talk.loc[talk['running_lines'] >= end_line].index[0]\n",
    "                        # C-5-e-5 - find in the talk the paragraph before the one above\n",
    "                        end_paragraph_2 = talk.loc[talk['running_lines'] >= end_line].index[-1]\n",
    "                        # C-5-e-6 - determine which paragraph would yield a number of lines being read closer to the target end line and save as end_paragraph\n",
    "                        if abs(talk.loc[end_paragraph_1,'running_lines'] - end_line) < abs(talk.loc[end_paragraph_2,'running_lines']- end_line):\n",
    "                            end_paragraph = end_paragraph_1\n",
    "                        else:\n",
    "                            end_paragraph = end_paragraph_2\n",
    "                        # C-5-e-7 - save the selected end_paragraph as the paragraph ending point of the current day of the current readthrough\n",
    "                        for end_p in end_p_col:\n",
    "                            conf_df.loc[index, end_p] = end_paragraph\n",
    "\n",
    "                        for end_p, next_start_p in zip(end_p_col, next_start_p_col):\n",
    "                            conf_df.loc[index, next_start_p] = conf_df.loc[index, end_p] + 1\n",
    "\n",
    "                        # debugging line - remove later\n",
    "                        print(f'Readthrough {rt} day {day} end paragraph set: End paragraph: {end_paragraph}')\n",
    "\n",
    "                # debugging print line - remove later\n",
    "                print(f'Readthrough {rt} columns day {day} saved. Looping back.')\n",
    "            \n",
    "            # debugging print line - remove later\n",
    "            print(f'Readthrough {rt} loop finished.')\n",
    "        \n",
    "        return conf_df\n",
    "    \n",
    "    # runs the get paragraphs function, saves as conf_df_7\n",
    "    conf_df_7 = get_paragraphs(conf_df_6, all_talks_dict)\n",
    "\n",
    "    \n",
    "    ##### Setting up and exporting final breakdown #####\n",
    "    \n",
    "    # establishes patterns for getting a list of start and end columns\n",
    "    start_cols_pat = r'r\\d+d\\d+_p_start'\n",
    "    end_cols_pat = r'r\\d+d\\d+_p_end'\n",
    "\n",
    "    # create a list of columns names in conf_df_7 \n",
    "    cols = list(conf_df_7.columns)\n",
    "\n",
    "    # initialize empty lists for start and end columns\n",
    "    final_start_cols = []\n",
    "    final_end_cols = []\n",
    "\n",
    "    # look at all of the column names in the column names list\n",
    "    for col in cols:\n",
    "        # if the column name matches the pattern for start columns, add it to the list of start columns\n",
    "        if re.search(start_cols_pat, col):\n",
    "            final_start_cols.append(col)\n",
    "        # if the column name matches the pattern for end columns, add it to the list of end columns\n",
    "        elif re.search(end_cols_pat, col):\n",
    "            final_end_cols.append(col)\n",
    "\n",
    "    # initialize an empty list for zipping the other two together\n",
    "        ## zipping two lists together basically entails combining them in the order of list 1 item 1, list 2 item 1, list 1 item 2, list 2 item 2, list 1 item 3, list 2 item 3, etc. \n",
    "    zipped_cols = []\n",
    "\n",
    "    # create a loop that 'zips' the start columns list and end columns list together\n",
    "    for start_col, end_col in zip(final_start_cols, final_end_cols):\n",
    "        zipped_cols.append(start_col)\n",
    "        zipped_cols.append(end_col)\n",
    "    \n",
    "    # create a list of necessary information columns\n",
    "    info_cols = ['Author', 'role', 'Title']\n",
    "\n",
    "    # combine the info_cols list and the zipped_cols list\n",
    "    final_cols = info_cols + zipped_cols\n",
    "\n",
    "    # keep only the columns in the final_cols list, save as final_breakdown\n",
    "    final_breakdown = conf_df_7[final_cols]\n",
    "\n",
    "    # Get user input about saving breakdown to computer\n",
    "    response_1 = input('Do you want to save the breakdown to your computer? ')\n",
    "    \n",
    "    # if the user wants to export the breakdown\n",
    "    if response_1.lower() == 'yes':\n",
    "        # ask the user where they want to store it\n",
    "        input_path = input(f'Please paste the location of the folder you would like to save the breakdown in: \\n'\n",
    "                           f'\\nFor example: D:\\Faith and Religion Stuff\\Come, Follow Me')\n",
    "        # add \\\\ to that path to make it compatible\n",
    "        path_start = f'{input_path}\\\\'\n",
    "        # ask the user if they want to use a custom name\n",
    "        response_2 = input('Would you like to save the file with a custom name?')\n",
    "        # if they do, ask the user for the custom name\n",
    "        if response_2.lower() == 'yes':\n",
    "            custom_name = input('Please enter the name you would like to save the file as: ')\n",
    "            name = f'{custom_name}.csv'\n",
    "        # otherwise generate a generic file name\n",
    "        else:\n",
    "            name = f'{month_year}_breakdown.csv'\n",
    "        \n",
    "        # combine the destination folder with the name of the file\n",
    "        final_path = os.path.join(path_start, name)\n",
    "        \n",
    "        # export final_breakdown as a csv to the destination folder\n",
    "        final_breakdown.to_csv(final_path, index=False)\n",
    "        \n",
    "    # Display the final breakdown for viewing in this notebook\n",
    "    return final_breakdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying alternative play button selector.\n",
      "Clicked the play button for The Triumph of Hope to start the media.\n",
      "Video element found in the DOM.\n",
      "No video or audio element found for The Triumph of Hope.\n",
      "Paragraph length of The Triumph of Hope: 44 paragraphs.\n",
      "Line length of The Triumph of Hope: 177 lines.\n",
      "Role of Neil L. Andersen: Of the Quorum of the Twelve Apostles\n",
      "Trying alternative play button selector.\n",
      "Clicked the play button for Live Up to Your Privileges to start the media.\n",
      "Video element found in the DOM.\n",
      "No video or audio element found for Live Up to Your Privileges.\n",
      "Paragraph length of Live Up to Your Privileges: 34 paragraphs.\n",
      "Line length of Live Up to Your Privileges: 170 lines.\n",
      "Role of Emily Belle Freeman: Young Women General President\n",
      "Trying alternative play button selector.\n",
      "Clicked the play button for God’s Favourite to start the media.\n",
      "Video element found in the DOM.\n",
      "No video or audio element found for God’s Favourite.\n",
      "Paragraph length of God’s Favourite: 20 paragraphs.\n",
      "Line length of God’s Favourite: 157 lines.\n",
      "Role of Karl D. Hirst: Of the Seventy\n",
      "Trying alternative play button selector.\n",
      "Clicked the play button for “This Is My Gospel”—“This Is My Church” to start the media.\n",
      "Video element found in the DOM.\n",
      "No video or audio element found for “This Is My Gospel”—“This Is My Church”.\n",
      "Paragraph length of “This Is My Gospel”—“This Is My Church”: 22 paragraphs.\n",
      "Line length of “This Is My Gospel”—“This Is My Church”: 181 lines.\n",
      "Role of Dale G. Renlund: Of the Quorum of the Twelve Apostles\n",
      "Trying alternative play button selector.\n",
      "Clicked the play button for Trusting Our Father to start the media.\n",
      "Video element found in the DOM.\n",
      "No video or audio element found for Trusting Our Father.\n",
      "Paragraph length of Trusting Our Father: 36 paragraphs.\n",
      "Line length of Trusting Our Father: 150 lines.\n",
      "Role of David P. Homer: Of the Seventy\n",
      "Trying alternative play button selector.\n",
      "Clicked the play button for God Loves All His Children to start the media.\n",
      "Video element found in the DOM.\n",
      "No video or audio element found for God Loves All His Children.\n",
      "Paragraph length of God Loves All His Children: 15 paragraphs.\n",
      "Line length of God Loves All His Children: 122 lines.\n",
      "Role of Gregorio E. Casillas: Of the Seventy\n",
      "Trying alternative play button selector.\n",
      "Clicked the play button for Following Christ to start the media.\n",
      "Video element found in the DOM.\n",
      "No video or audio element found for Following Christ.\n",
      "Paragraph length of Following Christ: 33 paragraphs.\n",
      "Line length of Following Christ: 161 lines.\n",
      "Role of Dallin H. Oaks: First Counselor in the First Presidency\n",
      "Trying alternative play button selector.\n",
      "Clicked the play button for Burying Our Weapons of Rebellion to start the media.\n",
      "Video element found in the DOM.\n",
      "No video or audio element found for Burying Our Weapons of Rebellion.\n",
      "Paragraph length of Burying Our Weapons of Rebellion: 30 paragraphs.\n",
      "Line length of Burying Our Weapons of Rebellion: 188 lines.\n",
      "Role of D. Todd Christofferson: Of the Quorum of the Twelve Apostles\n",
      "Trying alternative play button selector.\n",
      "Clicked the play button for Bonded to Jesus Christ: Becoming the Salt of the Earth to start the media.\n",
      "Video element found in the DOM.\n",
      "No video or audio element found for Bonded to Jesus Christ: Becoming the Salt of the Earth.\n",
      "Paragraph length of Bonded to Jesus Christ: Becoming the Salt of the Earth: 21 paragraphs.\n",
      "Line length of Bonded to Jesus Christ: Becoming the Salt of the Earth: 147 lines.\n",
      "Role of José A. Teixeira: Of the Presidency of the Seventy\n",
      "Trying alternative play button selector.\n",
      "Clicked the play button for His Hand Ready to Help Us to start the media.\n",
      "Video element found in the DOM.\n",
      "No video or audio element found for His Hand Ready to Help Us.\n",
      "Paragraph length of His Hand Ready to Help Us: 18 paragraphs.\n",
      "Line length of His Hand Ready to Help Us: 116 lines.\n",
      "Role of Juan Pablo Villar: Of the Seventy\n",
      "Trying alternative play button selector.\n",
      "Clicked the play button for Welcome to the Church of Joy to start the media.\n",
      "Video element found in the DOM.\n",
      "No video or audio element found for Welcome to the Church of Joy.\n",
      "Paragraph length of Welcome to the Church of Joy: 26 paragraphs.\n",
      "Line length of Welcome to the Church of Joy: 172 lines.\n",
      "Role of Patrick Kearon: Of the Quorum of the Twelve Apostles\n",
      "Trying alternative play button selector.\n",
      "Clicked the play button for “Ye Are My Friends” to start the media.\n",
      "Video element found in the DOM.\n"
     ]
    }
   ],
   "source": [
    "breakdown_gc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27 Jan 2025\n",
    "\n",
    "Upon trying to run the calculator above, I found that for some reason, the video/audio element was not being found, which was resulting in the function no longer being able to calculate the length of videos of these talks. I could spend a few days trying to get that up and working, but ultimately, I think that what will be easiest and simplest would be to forego any operations that require 'clicking play' and looking for the length of the video. I'll spend the rest of my time today trying to figure it out, and if I can't, I'll probably just move on.\n",
    "\n",
    "The main reason I think I'll just move on is that this calculator was working a few months ago when I calculated out the October 2024 General Conference, but now trying to work with the same conference, it's not working, suggesting that some back-end identifiers got updated or something. Even when I tried to run the function in my `Conference Calculator 1.0` notebook, I find that it is no longer able to find the play button for the videos. This suggests that just in the last few months the html code has been updated, and if I'm going to have to rebuild this every six months to accomodate that, it's probably not worth it, especially considering the marginal level of additional accuracy using the video lengths of each talk gives. \n",
    "\n",
    "So, that's a big thing to undo, I think: setting up this calculator to no longer use the video. That will speed it up and make it simpler. And, it seems that the number of lines and paragraphs are still calculating and counting, suggesting that although the video and play button tags have been updated, the tags for the text and paragraphs have not. \n",
    "\n",
    "I think that with the last few minutes I have today, I will breakdown the first aspect of the calculator, and see what I can do about making sure it is working. As I did before, I'm going to have to modularize this, and then put it all together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def system_setup_for_breakdown():\n",
    "    \"\"\"The purpose of this function is to import the packages I'll need for the breakdown to work properly and to set the working directory.\"\"\"\n",
    "\n",
    "    # import packages\n",
    "    import pandas as pd\n",
    "    print('Pandas imported as pd.')\n",
    "    import requests\n",
    "    print('Requests imported.')\n",
    "    from bs4 import BeautifulSoup\n",
    "    print('BeautifulSoup imported.')\n",
    "    import os\n",
    "    print('OS imported.')\n",
    "    import time\n",
    "    print('Time imported.')\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.chrome.service import Service\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium.webdriver.chrome.options import Options\n",
    "    print('Webdriver, Service, By, and Options imported from Selenium.')\n",
    "    from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    print('ChromeService, WebDriverWait, and ExpectedConditions imported from Selenium.')\n",
    "    import glob\n",
    "    print('Glob imported.')\n",
    "    from webdriver_manager.chrome import ChromeDriverManager\n",
    "    print('ChromeDriverManager imported.')\n",
    "    import re\n",
    "    print('Regular expression imported.')\n",
    "    from datetime import datetime, timedelta\n",
    "    print('Date and time imported.')\n",
    "\n",
    "    # Ask for input to establish the working directory\n",
    "    working_directory = input(\"Please enter the path to the directory you'd like to use for this calculator.\")\n",
    "    \n",
    "    # set working directory for accessing and saving files\n",
    "    os.chdir(working_directory)\n",
    "    print(f'Working directory set as [{os.getcwd()}].')\n",
    "    \n",
    "    #### save packages imported into list 'packages'\n",
    "    packages = [pd, requests, BeautifulSoup, os, time, \n",
    "                webdriver, Service, By, Options, ChromeService, \n",
    "                WebDriverWait, EC, glob, ChromeDriverManager, re, \n",
    "                datetime, timedelta]\n",
    "    \n",
    "    # return from running this function 'packages'\n",
    "    return packages\n",
    "\n",
    "\n",
    "#### Call the function and unpack the imports\n",
    "# pd, requests, BeautifulSoup, os, time, webdriver, Service, By, Options, ChromeService, WebDriverWait, EC, glob, ChromeDriverManager, re, datetime, timedelta = system_setup_for_breakdown()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we'll call that good for the day. The first modular aspect of my breakdown is working well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Feb 2025\n",
    "\n",
    "Okay, now I need to work on the next step of the breakdown. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_ini_inputs():\n",
    "    # ask for user input for link\n",
    "    conf_link = input('Please paste the link to the landing page of the conference you would like to breakdown.')\n",
    "    #### print conference link\n",
    "    print(f'Conference Link: {conf_link}')\n",
    "\n",
    "    # ask for user input for year and month of conference\n",
    "    month = input('Please enter whether the conference was held in April or October: ').lower().replace('il','',1).replace('ober','',1)\n",
    "    year = input('Please enter the year of the conference: ').strip().replace('20','',1)\n",
    "    month_year = month + year\n",
    "    #### print month_year\n",
    "    print(f'Conference Month-year: {month_year}')\n",
    "\n",
    "    # ask for user input for the start date and end dates\n",
    "    ini_start = str(input(\"What day would you like to start reading?\"))\n",
    "    ini_end = str(input(\"What day would you like to stop reading?\"))\n",
    "    #### print ini_start and ini_end\n",
    "    print(f'ini_start: {ini_start}')\n",
    "    print(f'ini_end: {ini_end}')\n",
    "\n",
    "    # Convert user input into datetime objects\n",
    "    ini_start_date = pd.to_datetime(ini_start,format='%m/%d/%Y')\n",
    "    ini_end_date = pd.to_datetime(ini_end,format='%m/%d/%Y')\n",
    "    #### print ini_start_date and ini_end_date\n",
    "    print(f'ini_start as datetime: {ini_start_date}')\n",
    "    print(f'ini_end as datetime: {ini_end_date}')\n",
    "    \n",
    "    # Get the total number of days for the breakdown plan\n",
    "    ini_total_days = ini_end_date - (ini_start_date - timedelta(days=1))\n",
    "    #### print total number of days to be calculated over\n",
    "    print(f'Total number of days: {ini_total_days.days}')\n",
    "\n",
    "    ini_inputs = [conf_link, month_year, ini_start_date, ini_end_date, ini_total_days]\n",
    "\n",
    "    return ini_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Call the function and unpack the imports\n",
    "# pd, requests, BeautifulSoup, os, time, webdriver, Service, By, Options, ChromeService, WebDriverWait, EC, glob, ChromeDriverManager, re, datetime, timedelta = system_setup_for_breakdown()\n",
    "\n",
    "# conf_link, month_year, ini_start_date, ini_end_date, ini_total_days = set_ini_inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I immediately ran into the problem of the packages only being imported within the `system_setup_for_breakdown` function. So, I modified it above to see if that will work. I modified the code above (defining the `system_setup_for_breakdown` function) by adding a line that saves the packages in a list, and changing how I use the function. Rather than just running it, I run it as saving the packages as different items that the function returns. All this simply overcomes that fact that packages imported inside a function are only imported for that function as stop working as soon as that function ends. \n",
    "\n",
    "And it worked, as shown by the output above. \n",
    "\n",
    "Now for the third chunk of the overall function - getting the initial information about each talk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landing_page_info():\n",
    "    '''\n",
    "    This function uses requests and ChromeDriver to navigate to the conf_link landing page and get information such as author, title, and description of each talk on the landing page of the conference.\n",
    "    '''\n",
    "    # get response\n",
    "    response = requests.get(conf_link)\n",
    "\n",
    "    # Define the path to the chromedriver executable\n",
    "    chrome_driver_dir = r'D:\\\\Faith and Religion Stuff\\\\Come, Follow Me\\\\chromedriver-win64'\n",
    "    chrome_driver_path = os.path.join(chrome_driver_dir, 'chromedriver.exe')\n",
    "\n",
    "    # Set up the headless browser options\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "\n",
    "    # Set up the Chrome service\n",
    "    service = Service(chrome_driver_path)    \n",
    "        \n",
    "    # Initialize the Chrome WebDriver\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    # Establish a try loop that tries to navigate to the provided link and find and store bits of info that we need \n",
    "    try:\n",
    "        # Navigate to the page with your elements - in this case the April 2024 General Conference\n",
    "        driver.get(conf_link)\n",
    "\n",
    "        # Find all elements with the specified class name\n",
    "        # Gotta use dots, not spaces, here because CSS considers each of those spaces to be defining a dif class object\n",
    "        elements = driver.find_elements(By.CSS_SELECTOR, 'a.sc-omeqik-0.ewktus.list-tile.listTile-WHLxI')  \n",
    "\n",
    "        # Initialize a list to store authors, titles, descriptions, and links\n",
    "        primary_meta_list = []\n",
    "        title_list = []\n",
    "        description_list = []\n",
    "        href_list = []\n",
    "\n",
    "        # Iterate over each element\n",
    "        # This for loop will, for all the videos/links to talks on the 2024 General Conference page, run through each of the following operations before moving onto the next\n",
    "        for element in elements:\n",
    "            # Try to get the author\n",
    "            try:\n",
    "                # Finds and stores the primary meta element (which is the author of the talk or report)\n",
    "                primary_meta_element = element.find_element(By.CSS_SELECTOR,'p.primaryMeta')\n",
    "                # Saves the stored author information as text\n",
    "                primary_meta = primary_meta_element.text\n",
    "            # If there is no author, save the author as None or Null\n",
    "            except:\n",
    "                primary_meta = None\n",
    "            # Adds the author (or the None) to the list of authors in the appropriate row\n",
    "            primary_meta_list.append(primary_meta)\n",
    "\n",
    "            # Try to get the title - every link/video should have a title\n",
    "            try:\n",
    "                # Finds and stores the title element (the title of the video, talk, or report)\n",
    "                title_element = element.find_element(By.CSS_SELECTOR,'p.title')\n",
    "                # Saves the stored title as text\n",
    "                title = title_element.text\n",
    "            # If there is no title, save the title as None - THIS SHOULD NEVER BE THE CASE\n",
    "            except:\n",
    "                title = None\n",
    "            # add the title (or the None) to the list of titles in the appropriate row\n",
    "            title_list.append(title)\n",
    "\n",
    "            # Try to get the description - the summary blurb about the video, talk, or report\n",
    "            try:\n",
    "                # Finds and stores the description element (the title of the video, talk, or report)\n",
    "                description_element = element.find_element(By.CSS_SELECTOR,'p.description')\n",
    "                # Saves the stored description as text\n",
    "                description = description_element.text\n",
    "            # If there is no description, save it as None - THIS SHOULD NEVER BE THE CASE\n",
    "            except:\n",
    "                description = None\n",
    "            # add the title (or the None) to the list of descriptions in the appropriate row\n",
    "            description_list.append(description)\n",
    "\n",
    "            # Finds and stores the link (or href) to the video, talk, or report\n",
    "            # This is ultimately going to be the information we use later to get the lengths (in paragraphs) of the talks and the lengths (in lines) of each of those paragraphs\n",
    "            href = element.get_attribute('href')\n",
    "            # Adds the stored href to the list of hrefs in the appropriate row\n",
    "            href_list.append(href)\n",
    "\n",
    "        # Creates a dataframe to store all the found and stored lists together\n",
    "        ini_conf_df = pd.DataFrame({\n",
    "            'Author': primary_meta_list,\n",
    "            'Title': title_list,\n",
    "            'Description': description_list,\n",
    "            'Link': href_list\n",
    "        })\n",
    "\n",
    "    # If anything doesn't work for some reason, tell why\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "    # After running everything, close the driver we opened to collect the data\n",
    "    finally:\n",
    "        # Close the browser\n",
    "        driver.quit()\n",
    "\n",
    "    return ini_conf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Call the function and unpack the imports\n",
    "# pd, requests, BeautifulSoup, os, time, webdriver, Service, By, Options, ChromeService, WebDriverWait, EC, glob, ChromeDriverManager, re, datetime, timedelta = system_setup_for_breakdown()\n",
    "\n",
    "# conf_link, month_year, ini_start_date, ini_end_date, ini_total_days = set_ini_inputs()\n",
    "\n",
    "# ini_conf_df = get_landing_page_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining the `get_landing_page_info` function, I tried to run it with the others and found that I needed to go back and set up the `set_ini_inputs` function to return all of those initial variables. Running the cell below, which displays the initially collected conference dataframe, shows that the three modular pieces I have created are all functioning properly together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ini_conf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I can move onto the next phase of the modularized function: cleaning up that initial dataframe to only contain the things I want, another easy bit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ini_df(conf_df):\n",
    "    \"\"\"This function removes rows from a dataframe based on the contents of their respective columns, and requires a conf_df as its input.\"\"\"\n",
    "\n",
    "    # initialize empty list of rows that need to be dropped\n",
    "    rows_to_drop = []\n",
    "\n",
    "    # Adds the indexes (or row numbers) of rows to the list of rows to be dropped if there is either no Author or Description\n",
    "        ## This exclusionary list is easy to edit\n",
    "    for index,row in conf_df.iterrows():\n",
    "        if row['Author'] == None:\n",
    "            rows_to_drop.append(index)\n",
    "        elif row['Description'] == None:\n",
    "            rows_to_drop.append(index)\n",
    "        elif 'Sustaining' in row['Title']:\n",
    "            rows_to_drop.append(index)\n",
    "        elif 'Audit' in row['Title']:\n",
    "            rows_to_drop.append(index)\n",
    "    \n",
    "    # Drops the rows in the list of rows to drop from the dataframe and resets the index\n",
    "        ## This eliminates from the dataframe the session videos and the sustaining of the officers of the Church\n",
    "    conf_df_1 = conf_df.drop(rows_to_drop).reset_index(drop=True)\n",
    "\n",
    "    return conf_df_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas imported as pd.\n",
      "Requests imported.\n",
      "BeautifulSoup imported.\n",
      "OS imported.\n",
      "Time imported.\n",
      "Webdriver, Service, By, and Options imported from Selenium.\n",
      "ChromeService, WebDriverWait, and ExpectedConditions imported from Selenium.\n",
      "Glob imported.\n",
      "ChromeDriverManager imported.\n",
      "Regular expression imported.\n",
      "Date and time imported.\n",
      "Working directory set as [D:\\Faith and Religion Stuff\\Come, Follow Me\\come-follow-me-breakdown-builder].\n",
      "Conference Link: https://www.churchofjesuschrist.org/study/general-conference/2024/10?lang=eng\n",
      "Conference Month-year: oct24\n",
      "ini_start: 10/10/2024\n",
      "ini_end: 4/4/2025\n",
      "ini_start as datetime: 2024-10-10 00:00:00\n",
      "ini_end as datetime: 2025-04-04 00:00:00\n",
      "Total number of days: 177\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neil L. Andersen</td>\n",
       "      <td>The Triumph of Hope</td>\n",
       "      <td>Elder Andersen teaches that when we have hope ...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emily Belle Freeman</td>\n",
       "      <td>Live Up to Your Privileges</td>\n",
       "      <td>President Freeman encourages women and young w...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Karl D. Hirst</td>\n",
       "      <td>God’s Favourite</td>\n",
       "      <td>Elder Hirst teaches us how to feel the divine ...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dale G. Renlund</td>\n",
       "      <td>“This Is My Gospel”—“This Is My Church”</td>\n",
       "      <td>Elder Renlund teaches that the combination of ...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David P. Homer</td>\n",
       "      <td>Trusting Our Father</td>\n",
       "      <td>Elder Homer teaches that we receive blessings ...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gregorio E. Casillas</td>\n",
       "      <td>God Loves All His Children</td>\n",
       "      <td>Elder Casillas teaches that we can bless the l...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dallin H. Oaks</td>\n",
       "      <td>Following Christ</td>\n",
       "      <td>President Oaks teaches the importance of follo...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D. Todd Christofferson</td>\n",
       "      <td>Burying Our Weapons of Rebellion</td>\n",
       "      <td>Elder Christofferson encourages us to bury any...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>José A. Teixeira</td>\n",
       "      <td>Bonded to Jesus Christ: Becoming the Salt of t...</td>\n",
       "      <td>Elder Teixeira teaches four simple but profoun...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Juan Pablo Villar</td>\n",
       "      <td>His Hand Ready to Help Us</td>\n",
       "      <td>Elder Villar teaches that the Savior is always...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Patrick Kearon</td>\n",
       "      <td>Welcome to the Church of Joy</td>\n",
       "      <td>Elder Kearon teaches about the joy that can be...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>David L. Buckner</td>\n",
       "      <td>“Ye Are My Friends”</td>\n",
       "      <td>Elder Buckner teaches that we must stop lookin...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>D. Martin Goury</td>\n",
       "      <td>Be Thou Clean</td>\n",
       "      <td>Elder Goury teaches that daily repentance help...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Aroldo B. Cavalcante</td>\n",
       "      <td>The Wind Did Never Cease to Blow</td>\n",
       "      <td>Elder Cavalcante teaches that God can sustain ...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Ulisses Soares</td>\n",
       "      <td>Aligning Our Will with His</td>\n",
       "      <td>Elder Soares teaches that the ultimate test of...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Gerrit W. Gong</td>\n",
       "      <td>Holiness to the Lord in Everyday Life</td>\n",
       "      <td>Elder Gong invites us to make holiness part of...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kristin M. Yee</td>\n",
       "      <td>The Joy of Our Redemption</td>\n",
       "      <td>Sister Yee teaches that through our covenant r...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Kyle S. McKay</td>\n",
       "      <td>The Man Who Communed with Jehovah</td>\n",
       "      <td>Elder McKay gives his witness of the great lif...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Jorge M. Alvarado</td>\n",
       "      <td>Embrace the Lord’s Gift of Repentance</td>\n",
       "      <td>Elder Alvarado teaches about repentance and te...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>David A. Bednar</td>\n",
       "      <td>In the Space of Not Many Years</td>\n",
       "      <td>Elder Bednar uses the examples of the Nephites...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Jeffrey R. Holland</td>\n",
       "      <td>“I Am He”</td>\n",
       "      <td>President Holland teaches about Christ’s compl...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Tracy Y. Browning</td>\n",
       "      <td>Seeking Answers to Spiritual Questions</td>\n",
       "      <td>Sister Browning teaches that God can help us g...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Brook P. Hales</td>\n",
       "      <td>Mortality Works!</td>\n",
       "      <td>Elder Hales teaches that because of the gospel...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>L. Todd Budge</td>\n",
       "      <td>Seek Him with All Your Heart</td>\n",
       "      <td>Bishop Budge speaks about the importance of qu...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Gary E. Stevenson</td>\n",
       "      <td>Days Never to Be Forgotten</td>\n",
       "      <td>Elder Stevenson looks ahead to the next 10 yea...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Bradley R. Wilcox</td>\n",
       "      <td>O Youth of the Noble Birthright</td>\n",
       "      <td>Speaking to youth, Brother Wilcox addresses th...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Henry B. Eyring</td>\n",
       "      <td>Simple Is the Doctrine of Jesus Christ</td>\n",
       "      <td>President Eyring encourages us to teach the tr...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Dieter F. Uchtdorf</td>\n",
       "      <td>Nourish the Roots, and the Branches Will Grow</td>\n",
       "      <td>Elder Uchtdorf teaches that the branches of ou...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Takashi Wada</td>\n",
       "      <td>The Words of Christ and the Holy Ghost Will Le...</td>\n",
       "      <td>Elder Wada teaches how feasting on the words o...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Ronald A. Rasband</td>\n",
       "      <td>“Behold I Am the Light Which Ye Shall Hold Up”</td>\n",
       "      <td>Elder Rasband teaches about sustaining the liv...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Quentin L. Cook</td>\n",
       "      <td>Sacred Scriptures—the Foundations of Faith</td>\n",
       "      <td>Elder Cook teaches about the importance of the...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Rubén V. Alliaud</td>\n",
       "      <td>Sons and Daughters of God</td>\n",
       "      <td>Elder Alliaud teaches that we are all the lite...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I. Raymond Egbo</td>\n",
       "      <td>Focus on Jesus Christ and His Gospel</td>\n",
       "      <td>Elder Egbo teaches that when we focus on Jesus...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Russell M. Nelson</td>\n",
       "      <td>The Lord Jesus Christ Will Come Again</td>\n",
       "      <td>President Nelson teaches that now is the time ...</td>\n",
       "      <td>https://www.churchofjesuschrist.org/study/gene...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Author                                              Title  \\\n",
       "0         Neil L. Andersen                                The Triumph of Hope   \n",
       "1      Emily Belle Freeman                         Live Up to Your Privileges   \n",
       "2            Karl D. Hirst                                    God’s Favourite   \n",
       "3          Dale G. Renlund            “This Is My Gospel”—“This Is My Church”   \n",
       "4           David P. Homer                                Trusting Our Father   \n",
       "5     Gregorio E. Casillas                         God Loves All His Children   \n",
       "6           Dallin H. Oaks                                   Following Christ   \n",
       "7   D. Todd Christofferson                   Burying Our Weapons of Rebellion   \n",
       "8         José A. Teixeira  Bonded to Jesus Christ: Becoming the Salt of t...   \n",
       "9        Juan Pablo Villar                          His Hand Ready to Help Us   \n",
       "10          Patrick Kearon                       Welcome to the Church of Joy   \n",
       "11        David L. Buckner                                “Ye Are My Friends”   \n",
       "12         D. Martin Goury                                      Be Thou Clean   \n",
       "13    Aroldo B. Cavalcante                   The Wind Did Never Cease to Blow   \n",
       "14          Ulisses Soares                         Aligning Our Will with His   \n",
       "15          Gerrit W. Gong              Holiness to the Lord in Everyday Life   \n",
       "16          Kristin M. Yee                          The Joy of Our Redemption   \n",
       "17           Kyle S. McKay                  The Man Who Communed with Jehovah   \n",
       "18       Jorge M. Alvarado              Embrace the Lord’s Gift of Repentance   \n",
       "19         David A. Bednar                     In the Space of Not Many Years   \n",
       "20      Jeffrey R. Holland                                          “I Am He”   \n",
       "21       Tracy Y. Browning             Seeking Answers to Spiritual Questions   \n",
       "22          Brook P. Hales                                   Mortality Works!   \n",
       "23           L. Todd Budge                       Seek Him with All Your Heart   \n",
       "24       Gary E. Stevenson                         Days Never to Be Forgotten   \n",
       "25       Bradley R. Wilcox                    O Youth of the Noble Birthright   \n",
       "26         Henry B. Eyring             Simple Is the Doctrine of Jesus Christ   \n",
       "27      Dieter F. Uchtdorf      Nourish the Roots, and the Branches Will Grow   \n",
       "28            Takashi Wada  The Words of Christ and the Holy Ghost Will Le...   \n",
       "29       Ronald A. Rasband     “Behold I Am the Light Which Ye Shall Hold Up”   \n",
       "30         Quentin L. Cook         Sacred Scriptures—the Foundations of Faith   \n",
       "31        Rubén V. Alliaud                          Sons and Daughters of God   \n",
       "32         I. Raymond Egbo               Focus on Jesus Christ and His Gospel   \n",
       "33       Russell M. Nelson              The Lord Jesus Christ Will Come Again   \n",
       "\n",
       "                                          Description  \\\n",
       "0   Elder Andersen teaches that when we have hope ...   \n",
       "1   President Freeman encourages women and young w...   \n",
       "2   Elder Hirst teaches us how to feel the divine ...   \n",
       "3   Elder Renlund teaches that the combination of ...   \n",
       "4   Elder Homer teaches that we receive blessings ...   \n",
       "5   Elder Casillas teaches that we can bless the l...   \n",
       "6   President Oaks teaches the importance of follo...   \n",
       "7   Elder Christofferson encourages us to bury any...   \n",
       "8   Elder Teixeira teaches four simple but profoun...   \n",
       "9   Elder Villar teaches that the Savior is always...   \n",
       "10  Elder Kearon teaches about the joy that can be...   \n",
       "11  Elder Buckner teaches that we must stop lookin...   \n",
       "12  Elder Goury teaches that daily repentance help...   \n",
       "13  Elder Cavalcante teaches that God can sustain ...   \n",
       "14  Elder Soares teaches that the ultimate test of...   \n",
       "15  Elder Gong invites us to make holiness part of...   \n",
       "16  Sister Yee teaches that through our covenant r...   \n",
       "17  Elder McKay gives his witness of the great lif...   \n",
       "18  Elder Alvarado teaches about repentance and te...   \n",
       "19  Elder Bednar uses the examples of the Nephites...   \n",
       "20  President Holland teaches about Christ’s compl...   \n",
       "21  Sister Browning teaches that God can help us g...   \n",
       "22  Elder Hales teaches that because of the gospel...   \n",
       "23  Bishop Budge speaks about the importance of qu...   \n",
       "24  Elder Stevenson looks ahead to the next 10 yea...   \n",
       "25  Speaking to youth, Brother Wilcox addresses th...   \n",
       "26  President Eyring encourages us to teach the tr...   \n",
       "27  Elder Uchtdorf teaches that the branches of ou...   \n",
       "28  Elder Wada teaches how feasting on the words o...   \n",
       "29  Elder Rasband teaches about sustaining the liv...   \n",
       "30  Elder Cook teaches about the importance of the...   \n",
       "31  Elder Alliaud teaches that we are all the lite...   \n",
       "32  Elder Egbo teaches that when we focus on Jesus...   \n",
       "33  President Nelson teaches that now is the time ...   \n",
       "\n",
       "                                                 Link  \n",
       "0   https://www.churchofjesuschrist.org/study/gene...  \n",
       "1   https://www.churchofjesuschrist.org/study/gene...  \n",
       "2   https://www.churchofjesuschrist.org/study/gene...  \n",
       "3   https://www.churchofjesuschrist.org/study/gene...  \n",
       "4   https://www.churchofjesuschrist.org/study/gene...  \n",
       "5   https://www.churchofjesuschrist.org/study/gene...  \n",
       "6   https://www.churchofjesuschrist.org/study/gene...  \n",
       "7   https://www.churchofjesuschrist.org/study/gene...  \n",
       "8   https://www.churchofjesuschrist.org/study/gene...  \n",
       "9   https://www.churchofjesuschrist.org/study/gene...  \n",
       "10  https://www.churchofjesuschrist.org/study/gene...  \n",
       "11  https://www.churchofjesuschrist.org/study/gene...  \n",
       "12  https://www.churchofjesuschrist.org/study/gene...  \n",
       "13  https://www.churchofjesuschrist.org/study/gene...  \n",
       "14  https://www.churchofjesuschrist.org/study/gene...  \n",
       "15  https://www.churchofjesuschrist.org/study/gene...  \n",
       "16  https://www.churchofjesuschrist.org/study/gene...  \n",
       "17  https://www.churchofjesuschrist.org/study/gene...  \n",
       "18  https://www.churchofjesuschrist.org/study/gene...  \n",
       "19  https://www.churchofjesuschrist.org/study/gene...  \n",
       "20  https://www.churchofjesuschrist.org/study/gene...  \n",
       "21  https://www.churchofjesuschrist.org/study/gene...  \n",
       "22  https://www.churchofjesuschrist.org/study/gene...  \n",
       "23  https://www.churchofjesuschrist.org/study/gene...  \n",
       "24  https://www.churchofjesuschrist.org/study/gene...  \n",
       "25  https://www.churchofjesuschrist.org/study/gene...  \n",
       "26  https://www.churchofjesuschrist.org/study/gene...  \n",
       "27  https://www.churchofjesuschrist.org/study/gene...  \n",
       "28  https://www.churchofjesuschrist.org/study/gene...  \n",
       "29  https://www.churchofjesuschrist.org/study/gene...  \n",
       "30  https://www.churchofjesuschrist.org/study/gene...  \n",
       "31  https://www.churchofjesuschrist.org/study/gene...  \n",
       "32  https://www.churchofjesuschrist.org/study/gene...  \n",
       "33  https://www.churchofjesuschrist.org/study/gene...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the function and unpack the imports\n",
    "pd, requests, BeautifulSoup, os, time, webdriver, Service, By, Options, ChromeService, WebDriverWait, EC, glob, ChromeDriverManager, re, datetime, timedelta = system_setup_for_breakdown()\n",
    "\n",
    "# call set_ini_inputs and save outputs\n",
    "conf_link, month_year, ini_start_date, ini_end_date, ini_total_days = set_ini_inputs()\n",
    "\n",
    "# call get_landing_page_info and save as ini_conf_df\n",
    "ini_conf_df = get_landing_page_info()\n",
    "\n",
    "# run clean_ini_df on ini_conf_df and save as conf_df_1\n",
    "conf_df_1 = clean_ini_df(ini_conf_df)\n",
    "\n",
    "conf_df_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! That's good for the day. When running the cell above, it shows that all my modular pieces up to this point are functioning properly and working together the way they should!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Feb 2025\n",
    "\n",
    "After re-running my previous code to make sure it's running properly, I can now move on to getting the next bit of my code modularized and working with the rest. \n",
    "\n",
    "In my original code, I have a function that collects the lines, paragraphs, and video length all at once. I previously decided that I would not try to collect information about the video length, but I'm a wishy-washy person, so I think I'll try to modularize the video thing on it's own, so that if I can get it up and running, I can use it, but if I can't, I don't need to worry about it. That will just require creating a conditional operation later that only accounts for the video length if it is present. I'll start with the easy stuff, though, which is getting the lines and paragraphs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_line_count(url):\n",
    "        \"\"\"\n",
    "        This function was designed to gather paragraph and line length information about a general conference talk.\n",
    "        First, it uses a webdriver to navigate to a url and then finds the paragraphs within a body block, and gets the size of the rectangles within which each of those paragraphs are assigned to appear. \n",
    "        Then, calculates the height of each line, saves that number as an integer, and calculates how many of those lines would fit into the assigned rectangle. \n",
    "        Then, it adds the paragraph number and the number of lines in that paragraph to the previously created dataframe.\n",
    "        Finally, it calculates and returns the total number of lines in the talk by getting the sum of all paragraph lengths in lines. \n",
    "        \"\"\"\n",
    "        # Define the path to the chromedriver executable\n",
    "        chrome_driver_dir = r'D:\\\\Faith and Religion Stuff\\\\Come, Follow Me\\\\chromedriver-win64'\n",
    "        chrome_driver_path = os.path.join(chrome_driver_dir, 'chromedriver.exe')\n",
    "\n",
    "        # Set up the headless browser options\n",
    "        chrome_options = Options()\n",
    "        chrome_options.add_argument(\"--headless\")\n",
    "        chrome_options.add_argument(\"--disable-gpu\")\n",
    "        chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "\n",
    "        # Set up the Chrome service\n",
    "        service = Service(chrome_driver_path)    \n",
    "            \n",
    "        # Initialize the Chrome WebDriver\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "        \n",
    "        # initialize empty dataframe \"data_list\", with columns \"paragraph\" and \"lines\" being initially populated with NA values\n",
    "        data_list = pd.DataFrame()\n",
    "        data_list['paragraph'] = pd.NA\n",
    "        data_list['lines'] = pd.NA\n",
    "\n",
    "        # Find all elements containing the text\n",
    "        paragraphs = driver.find_elements(By.CSS_SELECTOR, '.body-block p')\n",
    "\n",
    "        # Iterate over each paragraph element\n",
    "        for index, paragraph in enumerate(paragraphs, start=1):\n",
    "            # Log paragraph number, since the paragraphs are not numbered. \n",
    "            paragraph_number = index\n",
    "\n",
    "            # Get the bounding rectangle of the element\n",
    "            rect = paragraph.rect\n",
    "\n",
    "            # Calculate line height\n",
    "            line_height_str = driver.execute_script(\"return window.getComputedStyle(arguments[0]).getPropertyValue('line-height');\", paragraph)\n",
    "            line_height_numeric = int(re.search(r'\\d+', line_height_str).group())  # Extract numeric value from string\n",
    "\n",
    "            # Calculate number of lines\n",
    "            num_lines = rect['height'] // line_height_numeric\n",
    "\n",
    "            # Append data dictionary to list\n",
    "            data_list.at[index,'paragraph'] = paragraph_number\n",
    "            data_list.at[index, 'lines'] = num_lines\n",
    "\n",
    "            total_lines = sum(data_list['lines'])\n",
    "        \n",
    "        return total_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lpr(conf_df):\n",
    "    \"\"\"This function is designed to work with a dataframe that has the title, author, and url for each talk listed on a page that lists conference talks. It applies the get_line_count to each row, and also tries to get the role of each speaker. It then stores collected info in appropriate columns.\"\"\"\n",
    "    # Define the path to the chromedriver executable\n",
    "    chrome_driver_dir = r'D:\\\\Faith and Religion Stuff\\\\Come, Follow Me\\\\chromedriver-win64'\n",
    "    chrome_driver_path = os.path.join(chrome_driver_dir, 'chromedriver.exe')\n",
    "\n",
    "    # Set up the headless browser options\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--window-size=1920x1080\")\n",
    "\n",
    "    # Set up the Chrome service\n",
    "    service = Service(chrome_driver_path)    \n",
    "        \n",
    "    # Initialize the Chrome WebDriver\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    # Initialize columns in the dataframe with NA values to later be filled\n",
    "    conf_df['paragraphs'] = pd.NA\n",
    "    conf_df['lines'] = pd.NA\n",
    "    conf_df['role'] = pd.NA\n",
    "\n",
    "     # iterate the following over each row in the apr_2024_df dataframe\n",
    "    for index, row in conf_df.iterrows():\n",
    "        # for each row, when the function calls for title, url, and author it is looking for the Title, Link, and Author columns in that row, respectively\n",
    "        title = row['Title']\n",
    "        url = row['Link']\n",
    "        author = row['Author']\n",
    "\n",
    "        # run the driver, navigating to the linked page in the row currently being worked on\n",
    "        driver.get(url)\n",
    "\n",
    "        # attempt to find the body block\n",
    "        try:\n",
    "            paragraphs = driver.find_elements(By.CSS_SELECTOR, '.body-block p')\n",
    "            # if body block is found, find the number of paragraphs, and save that number to the dataframe in the same row\n",
    "            conf_df.at[index, 'paragraphs'] = len(paragraphs)\n",
    "            # print a message giving the length of the talk in paragraphs\n",
    "            print(f\"Paragraph length of {title}: {len(paragraphs)} paragraphs.\")\n",
    "\n",
    "            # Use the get_line_count function to get the total number of lines in the talk\n",
    "            num_lines = get_line_count(url)\n",
    "            \n",
    "            # save the number of lines to the dataframe in the same row\n",
    "            conf_df.at[index, 'lines'] = num_lines\n",
    "            \n",
    "            # print a message telling the number of lines in the talk\n",
    "            print(f\"Line length of {title}: {num_lines} lines.\")\n",
    "\n",
    "        # if there is an error or a problem, print a message saying what the problem was, and try to get the next piece of information \n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating lines and paragraphs for {title}: {e}\")\n",
    "        \n",
    "        # try to find the author role\n",
    "        try:\n",
    "            role = driver.find_element(By.CLASS_NAME, 'author-role')\n",
    "            # if there is one, save it to the dataframe in the same row\n",
    "            conf_df.at[index, 'role'] = role.text\n",
    "            # print a message displaying the role of the author\n",
    "            print(f\"Role of {author}: {role.text}\")\n",
    "        # if there is an error or a problem, print a message saying what the problem was and then move onto the next row\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving role for {author}: {e}\")\n",
    "\n",
    "    # Close the browser after all rows have been iterated through\n",
    "    driver.quit()\n",
    "\n",
    "    # converts all numeric columns to integers for easier use later\n",
    "    conf_df['paragraphs'] = conf_df['paragraphs'].astype(int)\n",
    "    conf_df['lines'] = conf_df['lines'].astype(int)\n",
    "            \n",
    "    return conf_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas imported as pd.\n",
      "Requests imported.\n",
      "BeautifulSoup imported.\n",
      "OS imported.\n",
      "Time imported.\n",
      "Webdriver, Service, By, and Options imported from Selenium.\n",
      "ChromeService, WebDriverWait, and ExpectedConditions imported from Selenium.\n",
      "Glob imported.\n",
      "ChromeDriverManager imported.\n",
      "Regular expression imported.\n",
      "Date and time imported.\n",
      "Working directory set as [D:\\Faith and Religion Stuff\\Come, Follow Me\\come-follow-me-breakdown-builder].\n",
      "Conference Link: https://www.churchofjesuschrist.org/study/general-conference/2024/10?lang=eng\n",
      "Conference Month-year: oct24\n",
      "ini_start: 10/10/2024\n",
      "ini_end: 4/4/2025\n",
      "ini_start as datetime: 2024-10-10 00:00:00\n",
      "ini_end as datetime: 2025-04-04 00:00:00\n",
      "Total number of days: 177\n",
      "Paragraph length of The Triumph of Hope: 44 paragraphs.\n",
      "Error calculating lines and paragraphs for The Triumph of Hope: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Neil L. Andersen: Of the Quorum of the Twelve Apostles\n",
      "Paragraph length of Live Up to Your Privileges: 34 paragraphs.\n",
      "Error calculating lines and paragraphs for Live Up to Your Privileges: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Emily Belle Freeman: Young Women General President\n",
      "Paragraph length of God’s Favourite: 20 paragraphs.\n",
      "Error calculating lines and paragraphs for God’s Favourite: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Karl D. Hirst: Of the Seventy\n",
      "Paragraph length of “This Is My Gospel”—“This Is My Church”: 22 paragraphs.\n",
      "Error calculating lines and paragraphs for “This Is My Gospel”—“This Is My Church”: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Dale G. Renlund: Of the Quorum of the Twelve Apostles\n",
      "Paragraph length of Trusting Our Father: 36 paragraphs.\n",
      "Error calculating lines and paragraphs for Trusting Our Father: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of David P. Homer: Of the Seventy\n",
      "Paragraph length of God Loves All His Children: 15 paragraphs.\n",
      "Error calculating lines and paragraphs for God Loves All His Children: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Gregorio E. Casillas: Of the Seventy\n",
      "Paragraph length of Following Christ: 33 paragraphs.\n",
      "Error calculating lines and paragraphs for Following Christ: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Dallin H. Oaks: First Counselor in the First Presidency\n",
      "Paragraph length of Burying Our Weapons of Rebellion: 30 paragraphs.\n",
      "Error calculating lines and paragraphs for Burying Our Weapons of Rebellion: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of D. Todd Christofferson: Of the Quorum of the Twelve Apostles\n",
      "Paragraph length of Bonded to Jesus Christ: Becoming the Salt of the Earth: 21 paragraphs.\n",
      "Error calculating lines and paragraphs for Bonded to Jesus Christ: Becoming the Salt of the Earth: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of José A. Teixeira: Of the Presidency of the Seventy\n",
      "Paragraph length of His Hand Ready to Help Us: 18 paragraphs.\n",
      "Error calculating lines and paragraphs for His Hand Ready to Help Us: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Juan Pablo Villar: Of the Seventy\n",
      "Paragraph length of Welcome to the Church of Joy: 26 paragraphs.\n",
      "Error calculating lines and paragraphs for Welcome to the Church of Joy: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Patrick Kearon: Of the Quorum of the Twelve Apostles\n",
      "Paragraph length of “Ye Are My Friends”: 19 paragraphs.\n",
      "Error calculating lines and paragraphs for “Ye Are My Friends”: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of David L. Buckner: Of the Seventy\n",
      "Paragraph length of Be Thou Clean: 17 paragraphs.\n",
      "Error calculating lines and paragraphs for Be Thou Clean: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of D. Martin Goury: Of the Seventy\n",
      "Paragraph length of The Wind Did Never Cease to Blow: 31 paragraphs.\n",
      "Error calculating lines and paragraphs for The Wind Did Never Cease to Blow: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Aroldo B. Cavalcante: Of the Seventy\n",
      "Paragraph length of Aligning Our Will with His: 24 paragraphs.\n",
      "Error calculating lines and paragraphs for Aligning Our Will with His: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Ulisses Soares: Of the Quorum of the Twelve Apostles\n",
      "Paragraph length of Holiness to the Lord in Everyday Life: 51 paragraphs.\n",
      "Error calculating lines and paragraphs for Holiness to the Lord in Everyday Life: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Gerrit W. Gong: Of the Quorum of the Twelve Apostles\n",
      "Paragraph length of The Joy of Our Redemption: 35 paragraphs.\n",
      "Error calculating lines and paragraphs for The Joy of Our Redemption: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Kristin M. Yee: Second Counselor in the Relief Society General Presidency\n",
      "Paragraph length of The Man Who Communed with Jehovah: 30 paragraphs.\n",
      "Error calculating lines and paragraphs for The Man Who Communed with Jehovah: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Kyle S. McKay: Of the Seventy\n",
      "Paragraph length of Embrace the Lord’s Gift of Repentance: 39 paragraphs.\n",
      "Error calculating lines and paragraphs for Embrace the Lord’s Gift of Repentance: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Jorge M. Alvarado: Of the Seventy\n",
      "Paragraph length of In the Space of Not Many Years: 43 paragraphs.\n",
      "Error calculating lines and paragraphs for In the Space of Not Many Years: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of David A. Bednar: Of the Quorum of the Twelve Apostles\n",
      "Paragraph length of “I Am He”: 20 paragraphs.\n",
      "Error calculating lines and paragraphs for “I Am He”: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Jeffrey R. Holland: Acting President of the Quorum of the Twelve Apostles\n",
      "Paragraph length of Seeking Answers to Spiritual Questions: 23 paragraphs.\n",
      "Error calculating lines and paragraphs for Seeking Answers to Spiritual Questions: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Tracy Y. Browning: Second Counselor in the Primary General Presidency\n",
      "Paragraph length of Mortality Works!: 33 paragraphs.\n",
      "Error calculating lines and paragraphs for Mortality Works!: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Brook P. Hales: Of the Seventy\n",
      "Paragraph length of Seek Him with All Your Heart: 31 paragraphs.\n",
      "Error calculating lines and paragraphs for Seek Him with All Your Heart: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of L. Todd Budge: Second Counselor in the Presiding Bishopric\n",
      "Paragraph length of Days Never to Be Forgotten: 33 paragraphs.\n",
      "Error calculating lines and paragraphs for Days Never to Be Forgotten: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Gary E. Stevenson: Of the Quorum of the Twelve Apostles\n",
      "Paragraph length of O Youth of the Noble Birthright: 23 paragraphs.\n",
      "Error calculating lines and paragraphs for O Youth of the Noble Birthright: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Bradley R. Wilcox: First Counselor in the Young Men General Presidency\n",
      "Paragraph length of Simple Is the Doctrine of Jesus Christ: 34 paragraphs.\n",
      "Error calculating lines and paragraphs for Simple Is the Doctrine of Jesus Christ: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Henry B. Eyring: Second Counselor in the First Presidency\n",
      "Paragraph length of Nourish the Roots, and the Branches Will Grow: 39 paragraphs.\n",
      "Error calculating lines and paragraphs for Nourish the Roots, and the Branches Will Grow: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Dieter F. Uchtdorf: Of the Quorum of the Twelve Apostles\n",
      "Paragraph length of The Words of Christ and the Holy Ghost Will Lead Us to the Truth: 19 paragraphs.\n",
      "Error calculating lines and paragraphs for The Words of Christ and the Holy Ghost Will Lead Us to the Truth: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Takashi Wada: Of the Seventy\n",
      "Paragraph length of “Behold I Am the Light Which Ye Shall Hold Up”: 32 paragraphs.\n",
      "Error calculating lines and paragraphs for “Behold I Am the Light Which Ye Shall Hold Up”: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Ronald A. Rasband: Of the Quorum of the Twelve Apostles\n",
      "Paragraph length of Sacred Scriptures—the Foundations of Faith: 35 paragraphs.\n",
      "Error calculating lines and paragraphs for Sacred Scriptures—the Foundations of Faith: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Quentin L. Cook: Of the Quorum of the Twelve Apostles\n",
      "Paragraph length of Sons and Daughters of God: 32 paragraphs.\n",
      "Error calculating lines and paragraphs for Sons and Daughters of God: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Rubén V. Alliaud: Of the Seventy\n",
      "Paragraph length of Focus on Jesus Christ and His Gospel: 26 paragraphs.\n",
      "Error calculating lines and paragraphs for Focus on Jesus Christ and His Gospel: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of I. Raymond Egbo: Of the Seventy\n",
      "Paragraph length of The Lord Jesus Christ Will Come Again: 46 paragraphs.\n",
      "Error calculating lines and paragraphs for The Lord Jesus Christ Will Come Again: cannot access local variable 'total_lines' where it is not associated with a value\n",
      "Role of Russell M. Nelson: President of The Church of Jesus Christ of Latter-day Saints\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'NAType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m conf_df_1 \u001b[38;5;241m=\u001b[39m clean_ini_df(ini_conf_df)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# run get_lpr on conf_df_1 and save as conf_df_2\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m conf_df_2 \u001b[38;5;241m=\u001b[39m get_lpr(conf_df_1)\n",
      "Cell \u001b[1;32mIn[9], line 71\u001b[0m, in \u001b[0;36mget_lpr\u001b[1;34m(conf_df)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# converts all numeric columns to integers for easier use later\u001b[39;00m\n\u001b[0;32m     70\u001b[0m conf_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparagraphs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m conf_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparagraphs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m---> 71\u001b[0m conf_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlines\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m conf_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlines\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conf_df\n",
      "File \u001b[1;32mc:\\Users\\bfran\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:6534\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6530\u001b[0m     results \u001b[38;5;241m=\u001b[39m [ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[0;32m   6532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6533\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6534\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   6535\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6536\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bfran\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:414\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    412\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    416\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    417\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m    418\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    419\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[0;32m    420\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\bfran\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:354\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    355\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    357\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\bfran\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:616\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    598\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    614\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m--> 616\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m    618\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    620\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bfran\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:238\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    235\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 238\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\bfran\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:183\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    180\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 183\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\bfran\\anaconda3\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:134\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[1;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'NAType'"
     ]
    }
   ],
   "source": [
    "# Call the function and unpack the imports\n",
    "pd, requests, BeautifulSoup, os, time, webdriver, Service, By, Options, ChromeService, WebDriverWait, EC, glob, ChromeDriverManager, re, datetime, timedelta = system_setup_for_breakdown()\n",
    "\n",
    "# call set_ini_inputs and save outputs\n",
    "conf_link, month_year, ini_start_date, ini_end_date, ini_total_days = set_ini_inputs()\n",
    "\n",
    "# call get_landing_page_info and save as ini_conf_df\n",
    "ini_conf_df = get_landing_page_info()\n",
    "\n",
    "# run clean_ini_df on ini_conf_df and save as conf_df_1\n",
    "conf_df_1 = clean_ini_df(ini_conf_df)\n",
    "\n",
    "# run get_lpr on conf_df_1 and save as conf_df_2\n",
    "conf_df_2 = get_lpr(conf_df_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issues I have run into:\n",
    "* driver not defined - This seems to be an issue with the `get_line_counts` function. I addressed it by just redefining the driver within that code. \n",
    "* cannot access local variable 'total_lines' where it is not associated with a value - This is also an issue with the `get_line_counts` function. \n",
    "\n",
    "So, before I can insert the `get_line_counts` function into `get_lpr` and into my overall calculator, I need to get it up and running by applying it to individual links and trying to figure out what is wrong. \n",
    "\n",
    "I also need to remember to adapt the code that gets the paragraph counts to exclude 'paragraphs' that are actually just subtext for images included with the talks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
